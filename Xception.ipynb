{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_applications' has no attribute 'set_keras_submodules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fcd11e28651b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# keras imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m keras_applications.set_keras_submodules(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras_applications' has no attribute 'set_keras_submodules'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xception = keras.applications.Xception(include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = xception.output_shape\n",
    "out = xception.output\n",
    "out = keras.layers.GlobalAveragePooling2D()(out)\n",
    "out = keras.layers.Dense(512, activation='relu')(out)\n",
    "total_classes = 5\n",
    "predictions = keras.layers.Dense(total_classes, activation='softmax')(out)\n",
    "\n",
    "model = keras.models.Model(inputs=xception.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "    if 'block14' in layer.name:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "train_generator = datagen.flow_from_directory(train_dir, target_size = (224,224), classes = ['0','1','2','3','4'],class_mode ='categorical') \n",
    "batch_size = 32\n",
    "train_steps_per_epoch = len(os.listdir(train_dir))//batch_size\n",
    "adm = tf.keras.optimizers.Adam(lr = 0.05)\n",
    "model.compile(optimizer = adm, loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.savefig('loss_Xception_20190903')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Xception.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Xception.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_pretrained_layer = keras.backend.function([model.layers[0].input],\n",
    "                                  [model.layers[131].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(21972, 7, 7, 2048))\n",
    "train_labels = np.zeros(shape=(21972,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2240\n",
      "2272\n",
      "2304\n",
      "2336\n",
      "2368\n",
      "2400\n",
      "2432\n",
      "2464\n",
      "2496\n",
      "2528\n",
      "2560\n",
      "2592\n",
      "2624\n",
      "2656\n",
      "2688\n",
      "2720\n",
      "2752\n",
      "2784\n",
      "2816\n",
      "2848\n",
      "2880\n",
      "2912\n",
      "2944\n",
      "2976\n",
      "3008\n",
      "3040\n",
      "3072\n",
      "3104\n",
      "3136\n",
      "3168\n",
      "3200\n",
      "3232\n",
      "3264\n",
      "3296\n",
      "3328\n",
      "3360\n",
      "3392\n",
      "3424\n",
      "3456\n",
      "3488\n",
      "3520\n",
      "3552\n",
      "3584\n",
      "3616\n",
      "3648\n",
      "3680\n",
      "3712\n",
      "3744\n",
      "3776\n",
      "3808\n",
      "3840\n",
      "3872\n",
      "3904\n",
      "3936\n",
      "3968\n",
      "4000\n",
      "4032\n",
      "4064\n",
      "4096\n",
      "4128\n",
      "4160\n",
      "4192\n",
      "4224\n",
      "4256\n",
      "4288\n",
      "4320\n",
      "4352\n",
      "4384\n",
      "4416\n",
      "4448\n",
      "4480\n",
      "4512\n",
      "4544\n",
      "4576\n",
      "4608\n",
      "4640\n",
      "4672\n",
      "4704\n",
      "4736\n",
      "4768\n",
      "4800\n",
      "4832\n",
      "4864\n",
      "4896\n",
      "4928\n",
      "4960\n",
      "4992\n",
      "5024\n",
      "5056\n",
      "5088\n",
      "5120\n",
      "5152\n",
      "5184\n",
      "5216\n",
      "5248\n",
      "5280\n",
      "5312\n",
      "5344\n",
      "5376\n",
      "5408\n",
      "5440\n",
      "5472\n",
      "5504\n",
      "5536\n",
      "5568\n",
      "5600\n",
      "5632\n",
      "5664\n",
      "5696\n",
      "5728\n",
      "5760\n",
      "5792\n",
      "5824\n",
      "5856\n",
      "5888\n",
      "5920\n",
      "5952\n",
      "5984\n",
      "6016\n",
      "6048\n",
      "6080\n",
      "6112\n",
      "6144\n",
      "6176\n",
      "6208\n",
      "6240\n",
      "6272\n",
      "6304\n",
      "6336\n",
      "6368\n",
      "6400\n",
      "6432\n",
      "6464\n",
      "6496\n",
      "6528\n",
      "6560\n",
      "6592\n",
      "6624\n",
      "6656\n",
      "6688\n",
      "6720\n",
      "6752\n",
      "6784\n",
      "6816\n",
      "6848\n",
      "6880\n",
      "6912\n",
      "6944\n",
      "6976\n",
      "7008\n",
      "7040\n",
      "7072\n",
      "7104\n",
      "7136\n",
      "7168\n",
      "7200\n",
      "7232\n",
      "7264\n",
      "7296\n",
      "7328\n",
      "7360\n",
      "7392\n",
      "7424\n",
      "7456\n",
      "7488\n",
      "7520\n",
      "7552\n",
      "7584\n",
      "7616\n",
      "7648\n",
      "7680\n",
      "7712\n",
      "7744\n",
      "7776\n",
      "7808\n",
      "7840\n",
      "7872\n",
      "7904\n",
      "7936\n",
      "7968\n",
      "8000\n",
      "8032\n",
      "8064\n",
      "8096\n",
      "8128\n",
      "8160\n",
      "8192\n",
      "8224\n",
      "8256\n",
      "8288\n",
      "8320\n",
      "8352\n",
      "8384\n",
      "8416\n",
      "8448\n",
      "8480\n",
      "8512\n",
      "8544\n",
      "8576\n",
      "8608\n",
      "8640\n",
      "8672\n",
      "8704\n",
      "8736\n",
      "8768\n",
      "8800\n",
      "8832\n",
      "8864\n",
      "8896\n",
      "8928\n",
      "8960\n",
      "8992\n",
      "9024\n",
      "9056\n",
      "9088\n",
      "9120\n",
      "9152\n",
      "9184\n",
      "9216\n",
      "9248\n",
      "9280\n",
      "9312\n",
      "9344\n",
      "9376\n",
      "9408\n",
      "9440\n",
      "9472\n",
      "9504\n",
      "9536\n",
      "9568\n",
      "9600\n",
      "9632\n",
      "9664\n",
      "9696\n",
      "9728\n",
      "9760\n",
      "9792\n",
      "9824\n",
      "9856\n",
      "9888\n",
      "9920\n",
      "9952\n",
      "9984\n",
      "10016\n",
      "10048\n",
      "10080\n",
      "10112\n",
      "10144\n",
      "10176\n",
      "10208\n",
      "10240\n",
      "10272\n",
      "10304\n",
      "10336\n",
      "10368\n",
      "10400\n",
      "10432\n",
      "10464\n",
      "10496\n",
      "10528\n",
      "10560\n",
      "10592\n",
      "10624\n",
      "10656\n",
      "10688\n",
      "10720\n",
      "10752\n",
      "10784\n",
      "10816\n",
      "10848\n",
      "10880\n",
      "10912\n",
      "10944\n",
      "10976\n",
      "11008\n",
      "11040\n",
      "11072\n",
      "11104\n",
      "11136\n",
      "11168\n",
      "11200\n",
      "11232\n",
      "11264\n",
      "11296\n",
      "11328\n",
      "11360\n",
      "11392\n",
      "11424\n",
      "11456\n",
      "11488\n",
      "11520\n",
      "11552\n",
      "11584\n",
      "11616\n",
      "11648\n",
      "11680\n",
      "11712\n",
      "11744\n",
      "11776\n",
      "11808\n",
      "11840\n",
      "11872\n",
      "11904\n",
      "11936\n",
      "11968\n",
      "12000\n",
      "12032\n",
      "12064\n",
      "12096\n",
      "12128\n",
      "12160\n",
      "12192\n",
      "12224\n",
      "12256\n",
      "12288\n",
      "12320\n",
      "12352\n",
      "12384\n",
      "12416\n",
      "12448\n",
      "12480\n",
      "12512\n",
      "12544\n",
      "12576\n",
      "12608\n",
      "12640\n",
      "12672\n",
      "12704\n",
      "12736\n",
      "12768\n",
      "12800\n",
      "12832\n",
      "12864\n",
      "12896\n",
      "12928\n",
      "12960\n",
      "12992\n",
      "13024\n",
      "13056\n",
      "13088\n",
      "13120\n",
      "13152\n",
      "13184\n",
      "13216\n",
      "13248\n",
      "13280\n",
      "13312\n",
      "13344\n",
      "13376\n",
      "13408\n",
      "13440\n",
      "13472\n",
      "13504\n",
      "13536\n",
      "13568\n",
      "13600\n",
      "13632\n",
      "13664\n",
      "13696\n",
      "13728\n",
      "13760\n",
      "13792\n",
      "13824\n",
      "13856\n",
      "13888\n",
      "13920\n",
      "13952\n",
      "13984\n",
      "14016\n",
      "14048\n",
      "14080\n",
      "14112\n",
      "14144\n",
      "14176\n",
      "14208\n",
      "14240\n",
      "14272\n",
      "14304\n",
      "14336\n",
      "14368\n",
      "14400\n",
      "14432\n",
      "14464\n",
      "14496\n",
      "14528\n",
      "14560\n",
      "14592\n",
      "14624\n",
      "14656\n",
      "14688\n",
      "14720\n",
      "14752\n",
      "14784\n",
      "14816\n",
      "14848\n",
      "14880\n",
      "14912\n",
      "14944\n",
      "14976\n",
      "15008\n",
      "15040\n",
      "15072\n",
      "15104\n",
      "15136\n",
      "15168\n",
      "15200\n",
      "15232\n",
      "15264\n",
      "15296\n",
      "15328\n",
      "15360\n",
      "15392\n",
      "15424\n",
      "15456\n",
      "15488\n",
      "15520\n",
      "15552\n",
      "15584\n",
      "15616\n",
      "15648\n",
      "15680\n",
      "15712\n",
      "15744\n",
      "15776\n",
      "15808\n",
      "15840\n",
      "15872\n",
      "15904\n",
      "15936\n",
      "15968\n",
      "16000\n",
      "16032\n",
      "16064\n",
      "16096\n",
      "16128\n",
      "16160\n",
      "16192\n",
      "16224\n",
      "16256\n",
      "16288\n",
      "16320\n",
      "16352\n",
      "16384\n",
      "16416\n",
      "16448\n",
      "16480\n",
      "16512\n",
      "16544\n",
      "16576\n",
      "16608\n",
      "16640\n",
      "16672\n",
      "16704\n",
      "16736\n",
      "16768\n",
      "16800\n",
      "16832\n",
      "16864\n",
      "16896\n",
      "16928\n",
      "16960\n",
      "16992\n",
      "17024\n",
      "17056\n",
      "17088\n",
      "17120\n",
      "17152\n",
      "17184\n",
      "17216\n",
      "17248\n",
      "17280\n",
      "17312\n",
      "17344\n",
      "17376\n",
      "17408\n",
      "17440\n",
      "17472\n",
      "17504\n",
      "17536\n",
      "17568\n",
      "17600\n",
      "17632\n",
      "17664\n",
      "17696\n",
      "17728\n",
      "17760\n",
      "17792\n",
      "17824\n",
      "17856\n",
      "17888\n",
      "17920\n",
      "17952\n",
      "17984\n",
      "18016\n",
      "18048\n",
      "18080\n",
      "18112\n",
      "18144\n",
      "18176\n",
      "18208\n",
      "18240\n",
      "18272\n",
      "18304\n",
      "18336\n",
      "18368\n",
      "18400\n",
      "18432\n",
      "18464\n",
      "18496\n",
      "18528\n",
      "18560\n",
      "18592\n",
      "18624\n",
      "18656\n",
      "18688\n",
      "18720\n",
      "18752\n",
      "18784\n",
      "18816\n",
      "18848\n",
      "18880\n",
      "18912\n",
      "18944\n",
      "18976\n",
      "19008\n",
      "19040\n",
      "19072\n",
      "19104\n",
      "19136\n",
      "19168\n",
      "19200\n",
      "19232\n",
      "19264\n",
      "19296\n",
      "19328\n",
      "19360\n",
      "19392\n",
      "19424\n",
      "19456\n",
      "19488\n",
      "19520\n",
      "19552\n",
      "19584\n",
      "19616\n",
      "19648\n",
      "19680\n",
      "19712\n",
      "19744\n",
      "19776\n",
      "19808\n",
      "19840\n",
      "19872\n",
      "19904\n",
      "19936\n",
      "19968\n",
      "20000\n",
      "20032\n",
      "20064\n",
      "20096\n",
      "20128\n",
      "20160\n",
      "20192\n",
      "20224\n",
      "20256\n",
      "20288\n",
      "20320\n",
      "20352\n",
      "20384\n",
      "20416\n",
      "20448\n",
      "20480\n",
      "20512\n",
      "20544\n",
      "20576\n",
      "20608\n",
      "20640\n",
      "20672\n",
      "20704\n",
      "20736\n",
      "20768\n",
      "20800\n",
      "20832\n",
      "20864\n",
      "20896\n",
      "20928\n",
      "20960\n",
      "20992\n",
      "21024\n",
      "21056\n",
      "21088\n",
      "21120\n",
      "21152\n",
      "21184\n",
      "21216\n",
      "21248\n",
      "21280\n",
      "21312\n",
      "21344\n",
      "21376\n",
      "21408\n",
      "21440\n",
      "21472\n",
      "21504\n",
      "21536\n",
      "21568\n",
      "21600\n",
      "21632\n",
      "21664\n",
      "21696\n",
      "21728\n",
      "21760\n",
      "21792\n",
      "21812\n",
      "21844\n",
      "21876\n",
      "21908\n",
      "21940\n",
      "21972\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = get_last_pretrained_layer(inputs_batch)[0]\n",
    "    train_features[i : i + len(inputs_batch)] = features_batch\n",
    "    train_labels[i : i +len(inputs_batch)] = labels_batch\n",
    "    i += len(inputs_batch)\n",
    "    print(i)\n",
    "    if i+2 > len(train_features):\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (21972, 7 * 7 * 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.enable()\n",
    "del model, xception, train_generator; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a45a10a10b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feat_train, feat_test, labels_train, labels_test = train_test_split(train_features, train_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4726efceb0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y_train)):\n",
    "    \n",
    "    trn_x, trn_y = train[train_cols].iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    val_x, val_y = train[train_cols].iloc[val_idx], y_train.iloc[val_idx]\n",
    "    gc.collect()\n",
    "    dtrain = xgb.DMatrix(trn_x, trn_y, feature_names=trn_x.columns)\n",
    "    dval = xgb.DMatrix(val_x, val_y, feature_names=val_x.columns)\n",
    "    gc.collect()\n",
    "    \n",
    "    clf = xgb.train(params=params, dtrain=dtrain, num_boost_round=1500, evals=[(dtrain, \"Train\"), (dval, \"Val\")],\n",
    "        verbose_eval= 250, early_stopping_rounds=100) \n",
    "    gc.collect()\n",
    "    \n",
    "    oof_preds[val_idx] = clf.predict(xgb.DMatrix(val_x))\n",
    "    sub_preds += clf.predict(xgb.DMatrix(test[train_cols])) / folds.n_splits\n",
    "    gc.collect()\n",
    "    \n",
    "    xgbfir.saveXgbFI(clf, feature_names=trn_x.columns, OutputXlsxFile='ieee_xgbfir_%sFold.xlsx'%str(n_fold+1), MaxInteractionDepth=9, MaxHistograms=15)\n",
    "    gc.collect()\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n",
    "    fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('\\nFold %2d AUC %.6f & std %.6f' %(n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]), np.std([oof_preds[val_idx]])))\n",
    "    gc.collect()\n",
    "\n",
    "print('\\nCV AUC score %.6f & std %.6f' % (roc_auc_score(y_train, oof_preds), np.std((oof_preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5333f9f545e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbleh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multi:softprob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "X = feat_train\n",
    "bleh, y = np.where(labels_train)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "bleh, y_test = np.where(labels_test)\n",
    "print(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
