{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xception = keras.applications.Xception(include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = xception.output_shape\n",
    "out = xception.output\n",
    "out = keras.layers.GlobalAveragePooling2D()(out)\n",
    "out = keras.layers.Dense(512, activation='relu')(out)\n",
    "total_classes = 5\n",
    "predictions = keras.layers.Dense(total_classes, activation='softmax')(out)\n",
    "\n",
    "model = keras.models.Model(inputs=xception.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "cnt = 0\n",
    "for layer in model.layers:\n",
    "    if cnt>130:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31067 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "971/971 [==============================] - 6102s 6s/step - loss: 10.9034\n",
      "Epoch 2/15\n",
      "971/971 [==============================] - 6902s 7s/step - loss: 10.9114\n",
      "Epoch 3/15\n",
      "971/971 [==============================] - 7330s 8s/step - loss: 10.9112\n",
      "Epoch 4/15\n",
      "971/971 [==============================] - 6514s 7s/step - loss: 10.9116\n",
      "Epoch 5/15\n",
      "971/971 [==============================] - 6436s 7s/step - loss: 10.9118\n",
      "Epoch 6/15\n",
      "971/971 [==============================] - 6852s 7s/step - loss: 10.9117\n",
      "Epoch 7/15\n",
      "971/971 [==============================] - 6937s 7s/step - loss: 10.9122\n",
      "Epoch 8/15\n",
      "971/971 [==============================] - 6243s 6s/step - loss: 10.9119\n",
      "Epoch 9/15\n",
      "971/971 [==============================] - 6191s 6s/step - loss: 10.9121\n",
      "Epoch 10/15\n",
      "971/971 [==============================] - 6175s 6s/step - loss: 10.9118\n",
      "Epoch 11/15\n",
      "971/971 [==============================] - 7447s 8s/step - loss: 10.9117\n",
      "Epoch 12/15\n",
      "971/971 [==============================] - 9126s 9s/step - loss: 10.9117\n",
      "Epoch 13/15\n",
      "971/971 [==============================] - 11023s 11s/step - loss: 10.9116\n",
      "Epoch 14/15\n",
      "971/971 [==============================] - 7102s 7s/step - loss: 10.9117\n",
      "Epoch 15/15\n",
      "971/971 [==============================] - 6459s 7s/step - loss: 10.9114\n"
     ]
    }
   ],
   "source": [
    "# training_generator = BalancedBatchGenerator(X_train, y_train,\n",
    "#                                                 batch_size=1000,\n",
    "#                                                 random_state=42)\n",
    "#     model.fit_generator(generator=training_generator, epochs=5, verbose=1)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "train_generator = datagen.flow_from_directory(train_dir, target_size = (224,224), classes = ['0','1','2','3','4'],class_mode ='categorical') \n",
    "batch_size = 32\n",
    "train_steps_per_epoch = 30038//batch_size\n",
    "adm = tf.keras.optimizers.Adam(lr = 0.12)\n",
    "model.compile(optimizer = adm, loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.savefig('loss_Xception_20190904')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Xception_20190904.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Xception_20190904.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_pretrained_layer = keras.backend.function([model.layers[0].input],\n",
    "                                  [model.layers[131].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(21972, 7, 7, 2048))\n",
    "train_labels = np.zeros(shape=(21972,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2240\n",
      "2272\n",
      "2304\n",
      "2336\n",
      "2368\n",
      "2400\n",
      "2432\n",
      "2464\n",
      "2496\n",
      "2528\n",
      "2560\n",
      "2592\n",
      "2624\n",
      "2656\n",
      "2688\n",
      "2720\n",
      "2752\n",
      "2784\n",
      "2816\n",
      "2848\n",
      "2880\n",
      "2912\n",
      "2944\n",
      "2976\n",
      "3008\n",
      "3040\n",
      "3072\n",
      "3104\n",
      "3136\n",
      "3168\n",
      "3200\n",
      "3232\n",
      "3264\n",
      "3296\n",
      "3328\n",
      "3360\n",
      "3392\n",
      "3424\n",
      "3456\n",
      "3488\n",
      "3520\n",
      "3552\n",
      "3584\n",
      "3616\n",
      "3648\n",
      "3680\n",
      "3712\n",
      "3744\n",
      "3776\n",
      "3808\n",
      "3840\n",
      "3872\n",
      "3904\n",
      "3936\n",
      "3968\n",
      "4000\n",
      "4032\n",
      "4064\n",
      "4096\n",
      "4128\n",
      "4160\n",
      "4192\n",
      "4224\n",
      "4256\n",
      "4288\n",
      "4320\n",
      "4352\n",
      "4384\n",
      "4416\n",
      "4448\n",
      "4480\n",
      "4512\n",
      "4544\n",
      "4576\n",
      "4608\n",
      "4640\n",
      "4672\n",
      "4704\n",
      "4736\n",
      "4768\n",
      "4800\n",
      "4832\n",
      "4864\n",
      "4896\n",
      "4928\n",
      "4960\n",
      "4992\n",
      "5024\n",
      "5056\n",
      "5088\n",
      "5120\n",
      "5152\n",
      "5184\n",
      "5216\n",
      "5248\n",
      "5280\n",
      "5312\n",
      "5344\n",
      "5376\n",
      "5408\n",
      "5440\n",
      "5472\n",
      "5504\n",
      "5536\n",
      "5568\n",
      "5600\n",
      "5632\n",
      "5664\n",
      "5696\n",
      "5728\n",
      "5760\n",
      "5792\n",
      "5824\n",
      "5856\n",
      "5888\n",
      "5920\n",
      "5952\n",
      "5984\n",
      "6016\n",
      "6048\n",
      "6080\n",
      "6112\n",
      "6144\n",
      "6176\n",
      "6208\n",
      "6240\n",
      "6272\n",
      "6304\n",
      "6336\n",
      "6368\n",
      "6400\n",
      "6432\n",
      "6464\n",
      "6496\n",
      "6528\n",
      "6560\n",
      "6592\n",
      "6624\n",
      "6656\n",
      "6688\n",
      "6720\n",
      "6752\n",
      "6784\n",
      "6816\n",
      "6848\n",
      "6880\n",
      "6912\n",
      "6944\n",
      "6976\n",
      "7008\n",
      "7040\n",
      "7072\n",
      "7104\n",
      "7136\n",
      "7168\n",
      "7200\n",
      "7232\n",
      "7264\n",
      "7296\n",
      "7328\n",
      "7360\n",
      "7392\n",
      "7424\n",
      "7456\n",
      "7488\n",
      "7520\n",
      "7552\n",
      "7584\n",
      "7616\n",
      "7648\n",
      "7680\n",
      "7712\n",
      "7744\n",
      "7776\n",
      "7808\n",
      "7840\n",
      "7872\n",
      "7904\n",
      "7936\n",
      "7968\n",
      "8000\n",
      "8032\n",
      "8064\n",
      "8096\n",
      "8128\n",
      "8160\n",
      "8192\n",
      "8224\n",
      "8256\n",
      "8288\n",
      "8320\n",
      "8352\n",
      "8384\n",
      "8416\n",
      "8448\n",
      "8480\n",
      "8512\n",
      "8544\n",
      "8576\n",
      "8608\n",
      "8640\n",
      "8672\n",
      "8704\n",
      "8736\n",
      "8768\n",
      "8800\n",
      "8832\n",
      "8864\n",
      "8896\n",
      "8928\n",
      "8960\n",
      "8992\n",
      "9024\n",
      "9056\n",
      "9088\n",
      "9120\n",
      "9152\n",
      "9184\n",
      "9216\n",
      "9248\n",
      "9280\n",
      "9312\n",
      "9344\n",
      "9376\n",
      "9408\n",
      "9440\n",
      "9472\n",
      "9504\n",
      "9536\n",
      "9568\n",
      "9600\n",
      "9632\n",
      "9664\n",
      "9696\n",
      "9728\n",
      "9760\n",
      "9792\n",
      "9824\n",
      "9856\n",
      "9888\n",
      "9920\n",
      "9952\n",
      "9984\n",
      "10016\n",
      "10048\n",
      "10080\n",
      "10112\n",
      "10144\n",
      "10176\n",
      "10208\n",
      "10240\n",
      "10272\n",
      "10304\n",
      "10336\n",
      "10368\n",
      "10400\n",
      "10432\n",
      "10464\n",
      "10496\n",
      "10528\n",
      "10560\n",
      "10592\n",
      "10624\n",
      "10656\n",
      "10688\n",
      "10720\n",
      "10752\n",
      "10784\n",
      "10816\n",
      "10848\n",
      "10880\n",
      "10912\n",
      "10944\n",
      "10976\n",
      "11008\n",
      "11040\n",
      "11072\n",
      "11104\n",
      "11136\n",
      "11168\n",
      "11200\n",
      "11232\n",
      "11264\n",
      "11296\n",
      "11328\n",
      "11360\n",
      "11392\n",
      "11424\n",
      "11456\n",
      "11488\n",
      "11520\n",
      "11552\n",
      "11584\n",
      "11616\n",
      "11648\n",
      "11680\n",
      "11712\n",
      "11744\n",
      "11776\n",
      "11808\n",
      "11840\n",
      "11872\n",
      "11904\n",
      "11936\n",
      "11968\n",
      "12000\n",
      "12032\n",
      "12064\n",
      "12096\n",
      "12128\n",
      "12160\n",
      "12192\n",
      "12224\n",
      "12256\n",
      "12288\n",
      "12320\n",
      "12352\n",
      "12384\n",
      "12416\n",
      "12448\n",
      "12480\n",
      "12512\n",
      "12544\n",
      "12576\n",
      "12608\n",
      "12640\n",
      "12672\n",
      "12704\n",
      "12736\n",
      "12768\n",
      "12800\n",
      "12832\n",
      "12864\n",
      "12896\n",
      "12928\n",
      "12960\n",
      "12992\n",
      "13024\n",
      "13056\n",
      "13088\n",
      "13120\n",
      "13152\n",
      "13184\n",
      "13216\n",
      "13248\n",
      "13280\n",
      "13312\n",
      "13344\n",
      "13376\n",
      "13408\n",
      "13440\n",
      "13472\n",
      "13504\n",
      "13536\n",
      "13568\n",
      "13600\n",
      "13632\n",
      "13664\n",
      "13696\n",
      "13728\n",
      "13760\n",
      "13792\n",
      "13824\n",
      "13856\n",
      "13888\n",
      "13920\n",
      "13952\n",
      "13984\n",
      "14016\n",
      "14048\n",
      "14080\n",
      "14112\n",
      "14144\n",
      "14176\n",
      "14208\n",
      "14240\n",
      "14272\n",
      "14304\n",
      "14336\n",
      "14368\n",
      "14400\n",
      "14432\n",
      "14464\n",
      "14496\n",
      "14528\n",
      "14560\n",
      "14592\n",
      "14624\n",
      "14656\n",
      "14688\n",
      "14720\n",
      "14752\n",
      "14784\n",
      "14816\n",
      "14848\n",
      "14880\n",
      "14912\n",
      "14944\n",
      "14976\n",
      "15008\n",
      "15040\n",
      "15072\n",
      "15104\n",
      "15136\n",
      "15168\n",
      "15200\n",
      "15232\n",
      "15264\n",
      "15296\n",
      "15328\n",
      "15360\n",
      "15392\n",
      "15424\n",
      "15456\n",
      "15488\n",
      "15520\n",
      "15552\n",
      "15584\n",
      "15616\n",
      "15648\n",
      "15680\n",
      "15712\n",
      "15744\n",
      "15776\n",
      "15808\n",
      "15840\n",
      "15872\n",
      "15904\n",
      "15936\n",
      "15968\n",
      "16000\n",
      "16032\n",
      "16064\n",
      "16096\n",
      "16128\n",
      "16160\n",
      "16192\n",
      "16224\n",
      "16256\n",
      "16288\n",
      "16320\n",
      "16352\n",
      "16384\n",
      "16416\n",
      "16448\n",
      "16480\n",
      "16512\n",
      "16544\n",
      "16576\n",
      "16608\n",
      "16640\n",
      "16672\n",
      "16704\n",
      "16736\n",
      "16768\n",
      "16800\n",
      "16832\n",
      "16864\n",
      "16896\n",
      "16928\n",
      "16960\n",
      "16992\n",
      "17024\n",
      "17056\n",
      "17088\n",
      "17120\n",
      "17152\n",
      "17184\n",
      "17216\n",
      "17248\n",
      "17280\n",
      "17312\n",
      "17344\n",
      "17376\n",
      "17408\n",
      "17440\n",
      "17472\n",
      "17504\n",
      "17536\n",
      "17568\n",
      "17600\n",
      "17632\n",
      "17664\n",
      "17696\n",
      "17728\n",
      "17760\n",
      "17792\n",
      "17824\n",
      "17856\n",
      "17888\n",
      "17920\n",
      "17952\n",
      "17984\n",
      "18016\n",
      "18048\n",
      "18080\n",
      "18112\n",
      "18144\n",
      "18176\n",
      "18208\n",
      "18240\n",
      "18272\n",
      "18304\n",
      "18336\n",
      "18368\n",
      "18400\n",
      "18432\n",
      "18464\n",
      "18496\n",
      "18528\n",
      "18560\n",
      "18592\n",
      "18624\n",
      "18656\n",
      "18688\n",
      "18720\n",
      "18752\n",
      "18784\n",
      "18816\n",
      "18848\n",
      "18880\n",
      "18912\n",
      "18944\n",
      "18976\n",
      "19008\n",
      "19040\n",
      "19072\n",
      "19104\n",
      "19136\n",
      "19168\n",
      "19200\n",
      "19232\n",
      "19264\n",
      "19296\n",
      "19328\n",
      "19360\n",
      "19392\n",
      "19424\n",
      "19456\n",
      "19488\n",
      "19520\n",
      "19552\n",
      "19584\n",
      "19616\n",
      "19648\n",
      "19680\n",
      "19712\n",
      "19744\n",
      "19776\n",
      "19808\n",
      "19840\n",
      "19872\n",
      "19904\n",
      "19936\n",
      "19968\n",
      "20000\n",
      "20032\n",
      "20064\n",
      "20096\n",
      "20128\n",
      "20160\n",
      "20192\n",
      "20224\n",
      "20256\n",
      "20288\n",
      "20320\n",
      "20352\n",
      "20384\n",
      "20416\n",
      "20448\n",
      "20480\n",
      "20512\n",
      "20544\n",
      "20576\n",
      "20608\n",
      "20640\n",
      "20672\n",
      "20704\n",
      "20736\n",
      "20768\n",
      "20800\n",
      "20832\n",
      "20864\n",
      "20896\n",
      "20928\n",
      "20960\n",
      "20992\n",
      "21024\n",
      "21056\n",
      "21088\n",
      "21120\n",
      "21152\n",
      "21184\n",
      "21216\n",
      "21248\n",
      "21280\n",
      "21312\n",
      "21344\n",
      "21376\n",
      "21408\n",
      "21440\n",
      "21472\n",
      "21504\n",
      "21536\n",
      "21568\n",
      "21600\n",
      "21632\n",
      "21664\n",
      "21696\n",
      "21728\n",
      "21760\n",
      "21792\n",
      "21812\n",
      "21844\n",
      "21876\n",
      "21908\n",
      "21940\n",
      "21972\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = get_last_pretrained_layer(inputs_batch)[0]\n",
    "    train_features[i : i + len(inputs_batch)] = features_batch\n",
    "    train_labels[i : i +len(inputs_batch)] = labels_batch\n",
    "    i += len(inputs_batch)\n",
    "    print(i)\n",
    "    if i+2 > len(train_features):\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (21972, 7 * 7 * 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.enable()\n",
    "del model, xception, train_generator; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a45a10a10b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feat_train, feat_test, labels_train, labels_test = train_test_split(train_features, train_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4726efceb0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y_train)):\n",
    "    \n",
    "    trn_x, trn_y = train[train_cols].iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    val_x, val_y = train[train_cols].iloc[val_idx], y_train.iloc[val_idx]\n",
    "    gc.collect()\n",
    "    dtrain = xgb.DMatrix(trn_x, trn_y, feature_names=trn_x.columns)\n",
    "    dval = xgb.DMatrix(val_x, val_y, feature_names=val_x.columns)\n",
    "    gc.collect()\n",
    "    \n",
    "    clf = xgb.train(params=params, dtrain=dtrain, num_boost_round=1500, evals=[(dtrain, \"Train\"), (dval, \"Val\")],\n",
    "        verbose_eval= 250, early_stopping_rounds=100) \n",
    "    gc.collect()\n",
    "    \n",
    "    oof_preds[val_idx] = clf.predict(xgb.DMatrix(val_x))\n",
    "    sub_preds += clf.predict(xgb.DMatrix(test[train_cols])) / folds.n_splits\n",
    "    gc.collect()\n",
    "    \n",
    "    xgbfir.saveXgbFI(clf, feature_names=trn_x.columns, OutputXlsxFile='ieee_xgbfir_%sFold.xlsx'%str(n_fold+1), MaxInteractionDepth=9, MaxHistograms=15)\n",
    "    gc.collect()\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n",
    "    fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('\\nFold %2d AUC %.6f & std %.6f' %(n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]), np.std([oof_preds[val_idx]])))\n",
    "    gc.collect()\n",
    "\n",
    "print('\\nCV AUC score %.6f & std %.6f' % (roc_auc_score(y_train, oof_preds), np.std((oof_preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5333f9f545e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbleh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multi:softprob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "X = feat_train\n",
    "bleh, y = np.where(labels_train)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "bleh, y_test = np.where(labels_test)\n",
    "print(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
