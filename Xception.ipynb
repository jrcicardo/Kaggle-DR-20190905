{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5.h5'\n",
    "def get_preds_and_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Get predictions and labels from the generator\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for _ in range(int(np.ceil(generator.samples / batch_size))):\n",
    "        x, y = next(generator)\n",
    "        preds.append(model.predict(x))\n",
    "        labels.append(y)\n",
    "    # Flatten list of numpy arrays\n",
    "    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n",
    "\n",
    "class Metrics(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback for saving the best model\n",
    "    according to the Quadratic Weighted Kappa (QWK) metric\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \"\"\"\n",
    "        Initialize list of QWK scores on validation data\n",
    "        \"\"\"\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Gets QWK score on the validation data\n",
    "        \"\"\"\n",
    "        # Get predictions and convert to integers\n",
    "        y_pred, labels = get_preds_and_labels(model, val_generator)\n",
    "        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n",
    "        # We can use sklearns implementation of QWK straight out of the box\n",
    "        # as long as we specify weights as 'quadratic'\n",
    "        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic')\n",
    "        self.val_kappas.append(_val_kappa)\n",
    "        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n",
    "        if _val_kappa == max(self.val_kappas):\n",
    "            print(\"Validation Kappa has improved. Saving model.\")\n",
    "            self.model.save(SAVED_MODEL_NAME)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/data/'\n",
    "img_dir = train_dir + 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dir+'dr15labels_2.csv')\n",
    "train_df_2 = pd.read_csv('/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/drlabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = train_df.sample(frac = 0.2)\n",
    "sub2 = train_df_2.sample(frac = 0.2)\n",
    "subs = pd.concat([sub,sub2])\n",
    "val_sub = train_df.sample(frac = 0.05)\n",
    "val_sub2 = train_df_2.sample(frac = 0.05)\n",
    "val_subs = pd.concat([val_sub,val_sub2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs.columns = ['id_code','diagnosis']\n",
    "subs['diagnosis'] = subs['diagnosis'].astype(str)\n",
    "for ind in subs.index:\n",
    "    diag = subs['diagnosis'][ind]\n",
    "    subs['id_code'][ind] = img_dir+ str(diag) +'/'+ subs['id_code'][ind] +'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subs.columns = ['id_code','diagnosis']\n",
    "val_subs['diagnosis'] = val_subs['diagnosis'].astype(str)\n",
    "for ind in val_subs.index:\n",
    "    diag = val_subs['diagnosis'][ind]\n",
    "    val_subs['id_code'][ind] = img_dir+ str(diag) +'/'+ val_subs['id_code'][ind] +'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = keras.applications.Xception(include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = xception.output_shape\n",
    "out = xception.output\n",
    "out = keras.layers.GlobalAveragePooling2D()(out)\n",
    "out = keras.layers.Dense(512, activation='relu')(out)\n",
    "total_classes = 5\n",
    "predictions = keras.layers.Dense(total_classes, activation='softmax')(out)\n",
    "\n",
    "model = keras.models.Model(inputs=xception.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "cnt = 0\n",
    "for layer in model.layers:\n",
    "    if cnt>130:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5077 validated image filenames belonging to 5 classes.\n",
      "Found 1418 validated image filenames belonging to 5 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 2087 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 373 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "45/45 [==============================] - 273s 6s/step - loss: 9.3817\n",
      "val_kappa: 0.2216\n",
      "Validation Kappa has improved. Saving model.\n",
      "159/159 [==============================] - 1780s 11s/step - loss: 1.0359 - val_loss: 9.3817\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - 272s 6s/step - loss: 9.7342\n",
      "val_kappa: 0.2395\n",
      "Validation Kappa has improved. Saving model.\n",
      "159/159 [==============================] - 1746s 11s/step - loss: 0.9421 - val_loss: 9.7342\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - 271s 6s/step - loss: 9.8408\n",
      "val_kappa: 0.2386\n",
      "159/159 [==============================] - 1750s 11s/step - loss: 0.8997 - val_loss: 9.8408\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - 273s 6s/step - loss: 9.8285\n",
      "val_kappa: 0.2386\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "159/159 [==============================] - 1754s 11s/step - loss: 0.8434 - val_loss: 9.8285\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - 274s 6s/step - loss: 9.7909\n",
      "val_kappa: 0.2384\n",
      "159/159 [==============================] - 1754s 11s/step - loss: 0.7440 - val_loss: 9.7909\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - 269s 6s/step - loss: 9.8205\n",
      "val_kappa: 0.2392\n",
      "159/159 [==============================] - 1755s 11s/step - loss: 0.7181 - val_loss: 9.8205\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - 269s 6s/step - loss: 9.7445\n",
      "val_kappa: 0.2392\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "159/159 [==============================] - 1755s 11s/step - loss: 0.7019 - val_loss: 9.7445\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - 273s 6s/step - loss: 9.7686\n",
      "val_kappa: 0.2392\n",
      "159/159 [==============================] - 1758s 11s/step - loss: 0.6224 - val_loss: 9.7686\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - 271s 6s/step - loss: 9.7469\n",
      "val_kappa: 0.2392\n",
      "159/159 [==============================] - 1749s 11s/step - loss: 0.6092 - val_loss: 9.7469\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - 269s 6s/step - loss: 9.8436\n",
      "val_kappa: 0.2384\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "159/159 [==============================] - 1750s 11s/step - loss: 0.5827 - val_loss: 9.8436\n",
      "Epoch 11/150\n",
      "45/45 [==============================] - 265s 6s/step - loss: 9.7965\n",
      "val_kappa: 0.2392\n",
      "159/159 [==============================] - 1722s 11s/step - loss: 0.5504 - val_loss: 9.7965\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# training_generator = BalancedBatchGenerator(X_train, y_train,\n",
    "#                                                 batch_size=1000,\n",
    "#                                                 random_state=42)\n",
    "#     model.fit_generator(generator=training_generator, epochs=5, verbose=1)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 32\n",
    "train_steps_per_epoch = len(subs)//batch_size\n",
    "adm = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(subs, \n",
    "                                              x_col = 'id_code', \n",
    "                                              y_col = 'diagnosis',\n",
    "                                              target_size = (224,224),\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode ='categorical') \n",
    "val_generator = datagen.flow_from_dataframe(val_subs, \n",
    "                                            x_col='id_code', \n",
    "                                            y_col='diagnosis',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')\n",
    "# For tracking Quadratic Weighted Kappa score\n",
    "kappa_metrics = Metrics()\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                        factor=0.5, \n",
    "                        patience=3, \n",
    "                        verbose=1, \n",
    "                        mode='auto', \n",
    "                        epsilon=0.0001)\n",
    "\n",
    "model.compile(optimizer = adm, loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch, \n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps = val_generator.samples // batch_size,\n",
    "                              epochs=150, verbose=1, callbacks=[kappa_metrics, es, rlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.savefig('loss_Xception_20190905')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Xception_20190905.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Xception_20190905.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_pretrained_layer = keras.backend.function([model.layers[0].input],\n",
    "                                  [model.layers[131].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(21972, 7, 7, 2048))\n",
    "train_labels = np.zeros(shape=(21972,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2240\n",
      "2272\n",
      "2304\n",
      "2336\n",
      "2368\n",
      "2400\n",
      "2432\n",
      "2464\n",
      "2496\n",
      "2528\n",
      "2560\n",
      "2592\n",
      "2624\n",
      "2656\n",
      "2688\n",
      "2720\n",
      "2752\n",
      "2784\n",
      "2816\n",
      "2848\n",
      "2880\n",
      "2912\n",
      "2944\n",
      "2976\n",
      "3008\n",
      "3040\n",
      "3072\n",
      "3104\n",
      "3136\n",
      "3168\n",
      "3200\n",
      "3232\n",
      "3264\n",
      "3296\n",
      "3328\n",
      "3360\n",
      "3392\n",
      "3424\n",
      "3456\n",
      "3488\n",
      "3520\n",
      "3552\n",
      "3584\n",
      "3616\n",
      "3648\n",
      "3680\n",
      "3712\n",
      "3744\n",
      "3776\n",
      "3808\n",
      "3840\n",
      "3872\n",
      "3904\n",
      "3936\n",
      "3968\n",
      "4000\n",
      "4032\n",
      "4064\n",
      "4096\n",
      "4128\n",
      "4160\n",
      "4192\n",
      "4224\n",
      "4256\n",
      "4288\n",
      "4320\n",
      "4352\n",
      "4384\n",
      "4416\n",
      "4448\n",
      "4480\n",
      "4512\n",
      "4544\n",
      "4576\n",
      "4608\n",
      "4640\n",
      "4672\n",
      "4704\n",
      "4736\n",
      "4768\n",
      "4800\n",
      "4832\n",
      "4864\n",
      "4896\n",
      "4928\n",
      "4960\n",
      "4992\n",
      "5024\n",
      "5056\n",
      "5088\n",
      "5120\n",
      "5152\n",
      "5184\n",
      "5216\n",
      "5248\n",
      "5280\n",
      "5312\n",
      "5344\n",
      "5376\n",
      "5408\n",
      "5440\n",
      "5472\n",
      "5504\n",
      "5536\n",
      "5568\n",
      "5600\n",
      "5632\n",
      "5664\n",
      "5696\n",
      "5728\n",
      "5760\n",
      "5792\n",
      "5824\n",
      "5856\n",
      "5888\n",
      "5920\n",
      "5952\n",
      "5984\n",
      "6016\n",
      "6048\n",
      "6080\n",
      "6112\n",
      "6144\n",
      "6176\n",
      "6208\n",
      "6240\n",
      "6272\n",
      "6304\n",
      "6336\n",
      "6368\n",
      "6400\n",
      "6432\n",
      "6464\n",
      "6496\n",
      "6528\n",
      "6560\n",
      "6592\n",
      "6624\n",
      "6656\n",
      "6688\n",
      "6720\n",
      "6752\n",
      "6784\n",
      "6816\n",
      "6848\n",
      "6880\n",
      "6912\n",
      "6944\n",
      "6976\n",
      "7008\n",
      "7040\n",
      "7072\n",
      "7104\n",
      "7136\n",
      "7168\n",
      "7200\n",
      "7232\n",
      "7264\n",
      "7296\n",
      "7328\n",
      "7360\n",
      "7392\n",
      "7424\n",
      "7456\n",
      "7488\n",
      "7520\n",
      "7552\n",
      "7584\n",
      "7616\n",
      "7648\n",
      "7680\n",
      "7712\n",
      "7744\n",
      "7776\n",
      "7808\n",
      "7840\n",
      "7872\n",
      "7904\n",
      "7936\n",
      "7968\n",
      "8000\n",
      "8032\n",
      "8064\n",
      "8096\n",
      "8128\n",
      "8160\n",
      "8192\n",
      "8224\n",
      "8256\n",
      "8288\n",
      "8320\n",
      "8352\n",
      "8384\n",
      "8416\n",
      "8448\n",
      "8480\n",
      "8512\n",
      "8544\n",
      "8576\n",
      "8608\n",
      "8640\n",
      "8672\n",
      "8704\n",
      "8736\n",
      "8768\n",
      "8800\n",
      "8832\n",
      "8864\n",
      "8896\n",
      "8928\n",
      "8960\n",
      "8992\n",
      "9024\n",
      "9056\n",
      "9088\n",
      "9120\n",
      "9152\n",
      "9184\n",
      "9216\n",
      "9248\n",
      "9280\n",
      "9312\n",
      "9344\n",
      "9376\n",
      "9408\n",
      "9440\n",
      "9472\n",
      "9504\n",
      "9536\n",
      "9568\n",
      "9600\n",
      "9632\n",
      "9664\n",
      "9696\n",
      "9728\n",
      "9760\n",
      "9792\n",
      "9824\n",
      "9856\n",
      "9888\n",
      "9920\n",
      "9952\n",
      "9984\n",
      "10016\n",
      "10048\n",
      "10080\n",
      "10112\n",
      "10144\n",
      "10176\n",
      "10208\n",
      "10240\n",
      "10272\n",
      "10304\n",
      "10336\n",
      "10368\n",
      "10400\n",
      "10432\n",
      "10464\n",
      "10496\n",
      "10528\n",
      "10560\n",
      "10592\n",
      "10624\n",
      "10656\n",
      "10688\n",
      "10720\n",
      "10752\n",
      "10784\n",
      "10816\n",
      "10848\n",
      "10880\n",
      "10912\n",
      "10944\n",
      "10976\n",
      "11008\n",
      "11040\n",
      "11072\n",
      "11104\n",
      "11136\n",
      "11168\n",
      "11200\n",
      "11232\n",
      "11264\n",
      "11296\n",
      "11328\n",
      "11360\n",
      "11392\n",
      "11424\n",
      "11456\n",
      "11488\n",
      "11520\n",
      "11552\n",
      "11584\n",
      "11616\n",
      "11648\n",
      "11680\n",
      "11712\n",
      "11744\n",
      "11776\n",
      "11808\n",
      "11840\n",
      "11872\n",
      "11904\n",
      "11936\n",
      "11968\n",
      "12000\n",
      "12032\n",
      "12064\n",
      "12096\n",
      "12128\n",
      "12160\n",
      "12192\n",
      "12224\n",
      "12256\n",
      "12288\n",
      "12320\n",
      "12352\n",
      "12384\n",
      "12416\n",
      "12448\n",
      "12480\n",
      "12512\n",
      "12544\n",
      "12576\n",
      "12608\n",
      "12640\n",
      "12672\n",
      "12704\n",
      "12736\n",
      "12768\n",
      "12800\n",
      "12832\n",
      "12864\n",
      "12896\n",
      "12928\n",
      "12960\n",
      "12992\n",
      "13024\n",
      "13056\n",
      "13088\n",
      "13120\n",
      "13152\n",
      "13184\n",
      "13216\n",
      "13248\n",
      "13280\n",
      "13312\n",
      "13344\n",
      "13376\n",
      "13408\n",
      "13440\n",
      "13472\n",
      "13504\n",
      "13536\n",
      "13568\n",
      "13600\n",
      "13632\n",
      "13664\n",
      "13696\n",
      "13728\n",
      "13760\n",
      "13792\n",
      "13824\n",
      "13856\n",
      "13888\n",
      "13920\n",
      "13952\n",
      "13984\n",
      "14016\n",
      "14048\n",
      "14080\n",
      "14112\n",
      "14144\n",
      "14176\n",
      "14208\n",
      "14240\n",
      "14272\n",
      "14304\n",
      "14336\n",
      "14368\n",
      "14400\n",
      "14432\n",
      "14464\n",
      "14496\n",
      "14528\n",
      "14560\n",
      "14592\n",
      "14624\n",
      "14656\n",
      "14688\n",
      "14720\n",
      "14752\n",
      "14784\n",
      "14816\n",
      "14848\n",
      "14880\n",
      "14912\n",
      "14944\n",
      "14976\n",
      "15008\n",
      "15040\n",
      "15072\n",
      "15104\n",
      "15136\n",
      "15168\n",
      "15200\n",
      "15232\n",
      "15264\n",
      "15296\n",
      "15328\n",
      "15360\n",
      "15392\n",
      "15424\n",
      "15456\n",
      "15488\n",
      "15520\n",
      "15552\n",
      "15584\n",
      "15616\n",
      "15648\n",
      "15680\n",
      "15712\n",
      "15744\n",
      "15776\n",
      "15808\n",
      "15840\n",
      "15872\n",
      "15904\n",
      "15936\n",
      "15968\n",
      "16000\n",
      "16032\n",
      "16064\n",
      "16096\n",
      "16128\n",
      "16160\n",
      "16192\n",
      "16224\n",
      "16256\n",
      "16288\n",
      "16320\n",
      "16352\n",
      "16384\n",
      "16416\n",
      "16448\n",
      "16480\n",
      "16512\n",
      "16544\n",
      "16576\n",
      "16608\n",
      "16640\n",
      "16672\n",
      "16704\n",
      "16736\n",
      "16768\n",
      "16800\n",
      "16832\n",
      "16864\n",
      "16896\n",
      "16928\n",
      "16960\n",
      "16992\n",
      "17024\n",
      "17056\n",
      "17088\n",
      "17120\n",
      "17152\n",
      "17184\n",
      "17216\n",
      "17248\n",
      "17280\n",
      "17312\n",
      "17344\n",
      "17376\n",
      "17408\n",
      "17440\n",
      "17472\n",
      "17504\n",
      "17536\n",
      "17568\n",
      "17600\n",
      "17632\n",
      "17664\n",
      "17696\n",
      "17728\n",
      "17760\n",
      "17792\n",
      "17824\n",
      "17856\n",
      "17888\n",
      "17920\n",
      "17952\n",
      "17984\n",
      "18016\n",
      "18048\n",
      "18080\n",
      "18112\n",
      "18144\n",
      "18176\n",
      "18208\n",
      "18240\n",
      "18272\n",
      "18304\n",
      "18336\n",
      "18368\n",
      "18400\n",
      "18432\n",
      "18464\n",
      "18496\n",
      "18528\n",
      "18560\n",
      "18592\n",
      "18624\n",
      "18656\n",
      "18688\n",
      "18720\n",
      "18752\n",
      "18784\n",
      "18816\n",
      "18848\n",
      "18880\n",
      "18912\n",
      "18944\n",
      "18976\n",
      "19008\n",
      "19040\n",
      "19072\n",
      "19104\n",
      "19136\n",
      "19168\n",
      "19200\n",
      "19232\n",
      "19264\n",
      "19296\n",
      "19328\n",
      "19360\n",
      "19392\n",
      "19424\n",
      "19456\n",
      "19488\n",
      "19520\n",
      "19552\n",
      "19584\n",
      "19616\n",
      "19648\n",
      "19680\n",
      "19712\n",
      "19744\n",
      "19776\n",
      "19808\n",
      "19840\n",
      "19872\n",
      "19904\n",
      "19936\n",
      "19968\n",
      "20000\n",
      "20032\n",
      "20064\n",
      "20096\n",
      "20128\n",
      "20160\n",
      "20192\n",
      "20224\n",
      "20256\n",
      "20288\n",
      "20320\n",
      "20352\n",
      "20384\n",
      "20416\n",
      "20448\n",
      "20480\n",
      "20512\n",
      "20544\n",
      "20576\n",
      "20608\n",
      "20640\n",
      "20672\n",
      "20704\n",
      "20736\n",
      "20768\n",
      "20800\n",
      "20832\n",
      "20864\n",
      "20896\n",
      "20928\n",
      "20960\n",
      "20992\n",
      "21024\n",
      "21056\n",
      "21088\n",
      "21120\n",
      "21152\n",
      "21184\n",
      "21216\n",
      "21248\n",
      "21280\n",
      "21312\n",
      "21344\n",
      "21376\n",
      "21408\n",
      "21440\n",
      "21472\n",
      "21504\n",
      "21536\n",
      "21568\n",
      "21600\n",
      "21632\n",
      "21664\n",
      "21696\n",
      "21728\n",
      "21760\n",
      "21792\n",
      "21812\n",
      "21844\n",
      "21876\n",
      "21908\n",
      "21940\n",
      "21972\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = get_last_pretrained_layer(inputs_batch)[0]\n",
    "    train_features[i : i + len(inputs_batch)] = features_batch\n",
    "    train_labels[i : i +len(inputs_batch)] = labels_batch\n",
    "    i += len(inputs_batch)\n",
    "    print(i)\n",
    "    if i+2 > len(train_features):\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (21972, 7 * 7 * 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.enable()\n",
    "del model, xception, train_generator; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a45a10a10b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feat_train, feat_test, labels_train, labels_test = train_test_split(train_features, train_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4726efceb0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y_train)):\n",
    "    \n",
    "    trn_x, trn_y = train[train_cols].iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    val_x, val_y = train[train_cols].iloc[val_idx], y_train.iloc[val_idx]\n",
    "    gc.collect()\n",
    "    dtrain = xgb.DMatrix(trn_x, trn_y, feature_names=trn_x.columns)\n",
    "    dval = xgb.DMatrix(val_x, val_y, feature_names=val_x.columns)\n",
    "    gc.collect()\n",
    "    \n",
    "    clf = xgb.train(params=params, dtrain=dtrain, num_boost_round=1500, evals=[(dtrain, \"Train\"), (dval, \"Val\")],\n",
    "        verbose_eval= 250, early_stopping_rounds=100) \n",
    "    gc.collect()\n",
    "    \n",
    "    oof_preds[val_idx] = clf.predict(xgb.DMatrix(val_x))\n",
    "    sub_preds += clf.predict(xgb.DMatrix(test[train_cols])) / folds.n_splits\n",
    "    gc.collect()\n",
    "    \n",
    "    xgbfir.saveXgbFI(clf, feature_names=trn_x.columns, OutputXlsxFile='ieee_xgbfir_%sFold.xlsx'%str(n_fold+1), MaxInteractionDepth=9, MaxHistograms=15)\n",
    "    gc.collect()\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n",
    "    fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('\\nFold %2d AUC %.6f & std %.6f' %(n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]), np.std([oof_preds[val_idx]])))\n",
    "    gc.collect()\n",
    "\n",
    "print('\\nCV AUC score %.6f & std %.6f' % (roc_auc_score(y_train, oof_preds), np.std((oof_preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5333f9f545e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbleh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multi:softprob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "X = feat_train\n",
    "bleh, y = np.where(labels_train)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "bleh, y_test = np.where(labels_test)\n",
    "print(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
