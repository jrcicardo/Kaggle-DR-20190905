{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from keras==2.2.4) (5.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/flatironschool/.local/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: h5py in /Users/flatironschool/.local/lib/python3.6/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from keras==2.2.4) (1.3.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/flatironschool/.local/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/flatironschool/.local/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/flatironschool/.local/lib/python3.6/site-packages (from keras==2.2.4) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/function.py:987: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.keras as efn \n",
    "\n",
    "f7 = efn.EfficientNetB7(include_top = False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB7.h5'\n",
    "def get_preds_and_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Get predictions and labels from the generator\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for _ in range(int(np.ceil(generator.samples / batch_size))):\n",
    "        x, y = next(generator)\n",
    "        preds.append(model.predict(x))\n",
    "        labels.append(y)\n",
    "    # Flatten list of numpy arrays\n",
    "    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n",
    "\n",
    "class Metrics(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback for saving the best model\n",
    "    according to the Quadratic Weighted Kappa (QWK) metric\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \"\"\"\n",
    "        Initialize list of QWK scores on validation data\n",
    "        \"\"\"\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Gets QWK score on the validation data\n",
    "        \"\"\"\n",
    "        # Get predictions and convert to integers\n",
    "        y_pred, labels = get_preds_and_labels(model, val_generator)\n",
    "        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n",
    "        # We can use sklearns implementation of QWK straight out of the box\n",
    "        # as long as we specify weights as 'quadratic'\n",
    "        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic')\n",
    "        self.val_kappas.append(_val_kappa)\n",
    "        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n",
    "        if _val_kappa == max(self.val_kappas):\n",
    "            print(\"Validation Kappa has improved. Saving model.\")\n",
    "            self.model.save(SAVED_MODEL_NAME)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/data/'\n",
    "img_dir = train_dir + 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dir+'dr15labels_2.csv')\n",
    "train_df_2 = pd.read_csv('/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/drlabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = train_df.sample(frac = 0.2)\n",
    "sub2 = train_df_2.sample(frac = 0.2)\n",
    "subs = pd.concat([sub,sub2])\n",
    "val_sub = train_df.sample(frac = 0.05)\n",
    "val_sub2 = train_df_2.sample(frac = 0.05)\n",
    "val_subs = pd.concat([val_sub,val_sub2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs.columns = ['id_code','diagnosis']\n",
    "subs['diagnosis'] = subs['diagnosis'].astype(str)\n",
    "for ind in subs.index:\n",
    "    diag = subs['diagnosis'][ind]\n",
    "    subs['id_code'][ind] = img_dir+ str(diag) +'/'+ subs['id_code'][ind] +'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in f7.layers:\n",
    "    if 'block3' in layer.name:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subs.columns = ['id_code','diagnosis']\n",
    "val_subs['diagnosis'] = val_subs['diagnosis'].astype(str)\n",
    "for ind in val_subs.index:\n",
    "    diag = val_subs['diagnosis'][ind]\n",
    "    val_subs['id_code'][ind] = img_dir+ str(diag) +'/'+ val_subs['id_code'][ind] +'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_df,train_df_2])\n",
    "train.columns = ['id_code','diagnosis']\n",
    "train.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-a0debcacb4e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;31m# do the setitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[0;32m-> 2627\u001b[0;31m                                          force=True)\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ind in train.index:\n",
    "    diag = train['diagnosis'][ind]\n",
    "    train['id_code'][ind] = img_dir+ str(diag) +'/'+ train['id_code'][ind] +'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB7\n",
    "    for the APTOS 2019 competition\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(f7)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.Dense(5, activation='elu'))\n",
    "#     model.add(layers.Dense(1, activation=\"linear\"))\n",
    "#     print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.input_layer.InputLayer object at 0x14116da58&gt;</td>\n",
       "      <td>input_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x1437077b8&gt;</td>\n",
       "      <td>stem_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x143fb8518&gt;</td>\n",
       "      <td>stem_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x143fb8da0&gt;</td>\n",
       "      <td>stem_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.convolutional.DepthwiseConv2D object at 0x143fb8eb8&gt;</td>\n",
       "      <td>block1a_dwconv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x144470198&gt;</td>\n",
       "      <td>block1a_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x144470588&gt;</td>\n",
       "      <td>block1a_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D object at 0x144394898&gt;</td>\n",
       "      <td>block1a_se_squeeze</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;keras.layers.core.Reshape object at 0x144470390&gt;</td>\n",
       "      <td>block1a_se_reshape</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x144470400&gt;</td>\n",
       "      <td>block1a_se_reduce</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x144548358&gt;</td>\n",
       "      <td>block1a_se_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;keras.layers.merge.Multiply object at 0x144595198&gt;</td>\n",
       "      <td>block1a_se_excite</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x144595128&gt;</td>\n",
       "      <td>block1a_project_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x1445b06a0&gt;</td>\n",
       "      <td>block1a_project_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;keras.layers.convolutional.DepthwiseConv2D object at 0x1445b0470&gt;</td>\n",
       "      <td>block1b_dwconv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x144655c18&gt;</td>\n",
       "      <td>block1b_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x1446386d8&gt;</td>\n",
       "      <td>block1b_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D object at 0x1446ea908&gt;</td>\n",
       "      <td>block1b_se_squeeze</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;keras.layers.core.Reshape object at 0x144793c18&gt;</td>\n",
       "      <td>block1b_se_reshape</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x144698cf8&gt;</td>\n",
       "      <td>block1b_se_reduce</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x1447e7390&gt;</td>\n",
       "      <td>block1b_se_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;keras.layers.merge.Multiply object at 0x144808160&gt;</td>\n",
       "      <td>block1b_se_excite</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x1448082e8&gt;</td>\n",
       "      <td>block1b_project_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x1448262e8&gt;</td>\n",
       "      <td>block1b_project_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;efficientnet.model.get_dropout.&lt;locals&gt;.FixedDropout object at 0x144826630&gt;</td>\n",
       "      <td>block1b_drop</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x1448422b0&gt;</td>\n",
       "      <td>block1b_add</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;keras.layers.convolutional.DepthwiseConv2D object at 0x1448426a0&gt;</td>\n",
       "      <td>block1c_dwconv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x144842ac8&gt;</td>\n",
       "      <td>block1c_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x1449664e0&gt;</td>\n",
       "      <td>block1c_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D object at 0x1449b27b8&gt;</td>\n",
       "      <td>block1c_se_squeeze</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>&lt;keras.layers.convolutional.DepthwiseConv2D object at 0x150a7ad30&gt;</td>\n",
       "      <td>block7c_dwconv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x150a45eb8&gt;</td>\n",
       "      <td>block7c_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x150b3cf28&gt;</td>\n",
       "      <td>block7c_activation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D object at 0x150b921d0&gt;</td>\n",
       "      <td>block7c_se_squeeze</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>&lt;keras.layers.core.Reshape object at 0x150b74358&gt;</td>\n",
       "      <td>block7c_se_reshape</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x150b74080&gt;</td>\n",
       "      <td>block7c_se_reduce</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x150c849e8&gt;</td>\n",
       "      <td>block7c_se_expand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>&lt;keras.layers.merge.Multiply object at 0x150caa7b8&gt;</td>\n",
       "      <td>block7c_se_excite</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x150caa940&gt;</td>\n",
       "      <td>block7c_project_conv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x150cc9908&gt;</td>\n",
       "      <td>block7c_project_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>&lt;efficientnet.model.get_dropout.&lt;locals&gt;.FixedDropout object at 0x150cc9d30&gt;</td>\n",
       "      <td>block7c_drop</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x150d21e48&gt;</td>\n",
       "      <td>block7c_add</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x150ce5438&gt;</td>\n",
       "      <td>block7d_expand_conv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x150dd9978&gt;</td>\n",
       "      <td>block7d_expand_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x150dfde80&gt;</td>\n",
       "      <td>block7d_expand_activation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>&lt;keras.layers.convolutional.DepthwiseConv2D object at 0x150e57978&gt;</td>\n",
       "      <td>block7d_dwconv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x150e28be0&gt;</td>\n",
       "      <td>block7d_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x150f1ceb8&gt;</td>\n",
       "      <td>block7d_activation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D object at 0x150f6c5f8&gt;</td>\n",
       "      <td>block7d_se_squeeze</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>&lt;keras.layers.core.Reshape object at 0x150f1c5f8&gt;</td>\n",
       "      <td>block7d_se_reshape</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x150f1cc18&gt;</td>\n",
       "      <td>block7d_se_reduce</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x1510625c0&gt;</td>\n",
       "      <td>block7d_se_expand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>&lt;keras.layers.merge.Multiply object at 0x15108a390&gt;</td>\n",
       "      <td>block7d_se_excite</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x15108a518&gt;</td>\n",
       "      <td>block7d_project_conv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x1510a84a8&gt;</td>\n",
       "      <td>block7d_project_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>&lt;efficientnet.model.get_dropout.&lt;locals&gt;.FixedDropout object at 0x1510a8860&gt;</td>\n",
       "      <td>block7d_drop</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x1510c64e0&gt;</td>\n",
       "      <td>block7d_add</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x144271240&gt;</td>\n",
       "      <td>top_conv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization object at 0x1510e3630&gt;</td>\n",
       "      <td>top_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x1511b6780&gt;</td>\n",
       "      <td>top_activation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Layer Type  \\\n",
       "0    <keras.engine.input_layer.InputLayer object at 0x14116da58>                    \n",
       "1    <keras.layers.convolutional.Conv2D object at 0x1437077b8>                      \n",
       "2    <keras.layers.normalization.BatchNormalization object at 0x143fb8518>          \n",
       "3    <keras.layers.core.Activation object at 0x143fb8da0>                           \n",
       "4    <keras.layers.convolutional.DepthwiseConv2D object at 0x143fb8eb8>             \n",
       "5    <keras.layers.normalization.BatchNormalization object at 0x144470198>          \n",
       "6    <keras.layers.core.Activation object at 0x144470588>                           \n",
       "7    <keras.layers.pooling.GlobalAveragePooling2D object at 0x144394898>            \n",
       "8    <keras.layers.core.Reshape object at 0x144470390>                              \n",
       "9    <keras.layers.convolutional.Conv2D object at 0x144470400>                      \n",
       "10   <keras.layers.convolutional.Conv2D object at 0x144548358>                      \n",
       "11   <keras.layers.merge.Multiply object at 0x144595198>                            \n",
       "12   <keras.layers.convolutional.Conv2D object at 0x144595128>                      \n",
       "13   <keras.layers.normalization.BatchNormalization object at 0x1445b06a0>          \n",
       "14   <keras.layers.convolutional.DepthwiseConv2D object at 0x1445b0470>             \n",
       "15   <keras.layers.normalization.BatchNormalization object at 0x144655c18>          \n",
       "16   <keras.layers.core.Activation object at 0x1446386d8>                           \n",
       "17   <keras.layers.pooling.GlobalAveragePooling2D object at 0x1446ea908>            \n",
       "18   <keras.layers.core.Reshape object at 0x144793c18>                              \n",
       "19   <keras.layers.convolutional.Conv2D object at 0x144698cf8>                      \n",
       "20   <keras.layers.convolutional.Conv2D object at 0x1447e7390>                      \n",
       "21   <keras.layers.merge.Multiply object at 0x144808160>                            \n",
       "22   <keras.layers.convolutional.Conv2D object at 0x1448082e8>                      \n",
       "23   <keras.layers.normalization.BatchNormalization object at 0x1448262e8>          \n",
       "24   <efficientnet.model.get_dropout.<locals>.FixedDropout object at 0x144826630>   \n",
       "25   <keras.layers.merge.Add object at 0x1448422b0>                                 \n",
       "26   <keras.layers.convolutional.DepthwiseConv2D object at 0x1448426a0>             \n",
       "27   <keras.layers.normalization.BatchNormalization object at 0x144842ac8>          \n",
       "28   <keras.layers.core.Activation object at 0x1449664e0>                           \n",
       "29   <keras.layers.pooling.GlobalAveragePooling2D object at 0x1449b27b8>            \n",
       "..                                                                   ...            \n",
       "776  <keras.layers.convolutional.DepthwiseConv2D object at 0x150a7ad30>             \n",
       "777  <keras.layers.normalization.BatchNormalization object at 0x150a45eb8>          \n",
       "778  <keras.layers.core.Activation object at 0x150b3cf28>                           \n",
       "779  <keras.layers.pooling.GlobalAveragePooling2D object at 0x150b921d0>            \n",
       "780  <keras.layers.core.Reshape object at 0x150b74358>                              \n",
       "781  <keras.layers.convolutional.Conv2D object at 0x150b74080>                      \n",
       "782  <keras.layers.convolutional.Conv2D object at 0x150c849e8>                      \n",
       "783  <keras.layers.merge.Multiply object at 0x150caa7b8>                            \n",
       "784  <keras.layers.convolutional.Conv2D object at 0x150caa940>                      \n",
       "785  <keras.layers.normalization.BatchNormalization object at 0x150cc9908>          \n",
       "786  <efficientnet.model.get_dropout.<locals>.FixedDropout object at 0x150cc9d30>   \n",
       "787  <keras.layers.merge.Add object at 0x150d21e48>                                 \n",
       "788  <keras.layers.convolutional.Conv2D object at 0x150ce5438>                      \n",
       "789  <keras.layers.normalization.BatchNormalization object at 0x150dd9978>          \n",
       "790  <keras.layers.core.Activation object at 0x150dfde80>                           \n",
       "791  <keras.layers.convolutional.DepthwiseConv2D object at 0x150e57978>             \n",
       "792  <keras.layers.normalization.BatchNormalization object at 0x150e28be0>          \n",
       "793  <keras.layers.core.Activation object at 0x150f1ceb8>                           \n",
       "794  <keras.layers.pooling.GlobalAveragePooling2D object at 0x150f6c5f8>            \n",
       "795  <keras.layers.core.Reshape object at 0x150f1c5f8>                              \n",
       "796  <keras.layers.convolutional.Conv2D object at 0x150f1cc18>                      \n",
       "797  <keras.layers.convolutional.Conv2D object at 0x1510625c0>                      \n",
       "798  <keras.layers.merge.Multiply object at 0x15108a390>                            \n",
       "799  <keras.layers.convolutional.Conv2D object at 0x15108a518>                      \n",
       "800  <keras.layers.normalization.BatchNormalization object at 0x1510a84a8>          \n",
       "801  <efficientnet.model.get_dropout.<locals>.FixedDropout object at 0x1510a8860>   \n",
       "802  <keras.layers.merge.Add object at 0x1510c64e0>                                 \n",
       "803  <keras.layers.convolutional.Conv2D object at 0x144271240>                      \n",
       "804  <keras.layers.normalization.BatchNormalization object at 0x1510e3630>          \n",
       "805  <keras.layers.core.Activation object at 0x1511b6780>                           \n",
       "\n",
       "                    Layer Name  Layer Trainable  \n",
       "0    input_1                    False            \n",
       "1    stem_conv                  False            \n",
       "2    stem_bn                    False            \n",
       "3    stem_activation            False            \n",
       "4    block1a_dwconv             False            \n",
       "5    block1a_bn                 False            \n",
       "6    block1a_activation         False            \n",
       "7    block1a_se_squeeze         False            \n",
       "8    block1a_se_reshape         False            \n",
       "9    block1a_se_reduce          False            \n",
       "10   block1a_se_expand          False            \n",
       "11   block1a_se_excite          False            \n",
       "12   block1a_project_conv       False            \n",
       "13   block1a_project_bn         False            \n",
       "14   block1b_dwconv             False            \n",
       "15   block1b_bn                 False            \n",
       "16   block1b_activation         False            \n",
       "17   block1b_se_squeeze         False            \n",
       "18   block1b_se_reshape         False            \n",
       "19   block1b_se_reduce          False            \n",
       "20   block1b_se_expand          False            \n",
       "21   block1b_se_excite          False            \n",
       "22   block1b_project_conv       False            \n",
       "23   block1b_project_bn         False            \n",
       "24   block1b_drop               False            \n",
       "25   block1b_add                False            \n",
       "26   block1c_dwconv             False            \n",
       "27   block1c_bn                 False            \n",
       "28   block1c_activation         False            \n",
       "29   block1c_se_squeeze         False            \n",
       "..                  ...           ...            \n",
       "776  block7c_dwconv             True             \n",
       "777  block7c_bn                 True             \n",
       "778  block7c_activation         True             \n",
       "779  block7c_se_squeeze         True             \n",
       "780  block7c_se_reshape         True             \n",
       "781  block7c_se_reduce          True             \n",
       "782  block7c_se_expand          True             \n",
       "783  block7c_se_excite          True             \n",
       "784  block7c_project_conv       True             \n",
       "785  block7c_project_bn         True             \n",
       "786  block7c_drop               True             \n",
       "787  block7c_add                True             \n",
       "788  block7d_expand_conv        True             \n",
       "789  block7d_expand_bn          True             \n",
       "790  block7d_expand_activation  True             \n",
       "791  block7d_dwconv             True             \n",
       "792  block7d_bn                 True             \n",
       "793  block7d_activation         True             \n",
       "794  block7d_se_squeeze         True             \n",
       "795  block7d_se_reshape         True             \n",
       "796  block7d_se_reduce          True             \n",
       "797  block7d_se_expand          True             \n",
       "798  block7d_se_excite          True             \n",
       "799  block7d_project_conv       True             \n",
       "800  block7d_project_bn         True             \n",
       "801  block7d_drop               True             \n",
       "802  block7d_add                True             \n",
       "803  top_conv                   True             \n",
       "804  top_bn                     True             \n",
       "805  top_activation             True             \n",
       "\n",
       "[806 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in f7.layers]\n",
    "df_layers = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
    "df_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4248 validated image filenames belonging to 5 classes.\n",
      "Found 749 validated image filenames belonging to 5 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 2167 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 65/223 [=======>......................] - ETA: 4:26:45 - loss: 6.2830"
     ]
    }
   ],
   "source": [
    "# training_generator = BalancedBatchGenerator(X_train, y_train,\n",
    "#                                                 batch_size=1000,\n",
    "#                                                 random_state=42)\n",
    "#     model.fit_generator(generator=training_generator, epochs=5, verbose=1)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(validation_split = 0.15)\n",
    "batch_size = 32\n",
    "train_steps_per_epoch = len(subs)//batch_size\n",
    "adm = optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(subs, \n",
    "                                              x_col = 'id_code', \n",
    "                                              y_col = 'diagnosis',\n",
    "                                              target_size = (224,224),\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode ='categorical',\n",
    "                                              subset = 'training') \n",
    "val_generator = datagen.flow_from_dataframe(subs, \n",
    "                                            x_col='id_code', \n",
    "                                            y_col='diagnosis',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            subset = 'validation')\n",
    "# For tracking Quadratic Weighted Kappa score\n",
    "kappa_metrics = Metrics()\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                        factor=0.5, \n",
    "                        patience=3, \n",
    "                        verbose=1, \n",
    "                        mode='auto', \n",
    "                        epsilon=0.0001)\n",
    "\n",
    "model.compile(optimizer = adm, loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch, \n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps = val_generator.samples // batch_size,\n",
    "                              epochs=150, verbose=1, callbacks=[kappa_metrics, es, rlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.savefig('loss_f7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"f7.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"f7.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_pretrained_layer = keras.backend.function([model.layers[0].input],\n",
    "                                  [model.layers[131].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(21972, 7, 7, 2048))\n",
    "train_labels = np.zeros(shape=(21972,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = get_last_pretrained_layer(inputs_batch)[0]\n",
    "    train_features[i : i + len(inputs_batch)] = features_batch\n",
    "    train_labels[i : i +len(inputs_batch)] = labels_batch\n",
    "    i += len(inputs_batch)\n",
    "    print(i)\n",
    "    if i+2 > len(train_features):\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (21972, 7 * 7 * 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.enable()\n",
    "del model, xception, train_generator; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feat_train, feat_test, labels_train, labels_test = train_test_split(train_features, train_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y_train)):\n",
    "    \n",
    "    trn_x, trn_y = train[train_cols].iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    val_x, val_y = train[train_cols].iloc[val_idx], y_train.iloc[val_idx]\n",
    "    gc.collect()\n",
    "    dtrain = xgb.DMatrix(trn_x, trn_y, feature_names=trn_x.columns)\n",
    "    dval = xgb.DMatrix(val_x, val_y, feature_names=val_x.columns)\n",
    "    gc.collect()\n",
    "    \n",
    "    clf = xgb.train(params=params, dtrain=dtrain, num_boost_round=1500, evals=[(dtrain, \"Train\"), (dval, \"Val\")],\n",
    "        verbose_eval= 250, early_stopping_rounds=100) \n",
    "    gc.collect()\n",
    "    \n",
    "    oof_preds[val_idx] = clf.predict(xgb.DMatrix(val_x))\n",
    "    sub_preds += clf.predict(xgb.DMatrix(test[train_cols])) / folds.n_splits\n",
    "    gc.collect()\n",
    "    \n",
    "    xgbfir.saveXgbFI(clf, feature_names=trn_x.columns, OutputXlsxFile='ieee_xgbfir_%sFold.xlsx'%str(n_fold+1), MaxInteractionDepth=9, MaxHistograms=15)\n",
    "    gc.collect()\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n",
    "    fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('\\nFold %2d AUC %.6f & std %.6f' %(n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]), np.std([oof_preds[val_idx]])))\n",
    "    gc.collect()\n",
    "\n",
    "print('\\nCV AUC score %.6f & std %.6f' % (roc_auc_score(y_train, oof_preds), np.std((oof_preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat_train\n",
    "bleh, y = np.where(labels_train)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "bleh, y_test = np.where(labels_test)\n",
    "print(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
