{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.layers import Dense\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2019-08-23 14:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] successfully loaded base model and model...\n"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "# from keras.applications.xception import Xception, preprocess_input\n",
    "# from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "# from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from keras.preprocessing import image\n",
    "# from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "# load the user configs\n",
    "with open('conf/conf.json') as f:    \n",
    "    config = json.load(f)\n",
    "# config variables\n",
    "model_name = config[\"model\"]\n",
    "weights = config[\"weights\"]\n",
    "include_top = config[\"include_top\"]\n",
    "train_path = config[\"train_path\"]\n",
    "features_path = config[\"features_path\"]\n",
    "labels_path = config[\"labels_path\"]\n",
    "test_size = config[\"test_size\"]\n",
    "results = config[\"results\"]\n",
    "model_path = config[\"model_path\"]\n",
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "    base_model = VGG19(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "    base_model = keras.applications.ResNet50(include_top=False, weights=weights)\n",
    "    model = base_model\n",
    "#     model = Model(input=base_model.input, output=base_model.layers[-1].output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "    base_model = InceptionV3(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"inceptionresnetv2\":\n",
    "    base_model = InceptionResNetV2(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "#     model = Model(input=base_model.input, output=base_model.layers[-1].output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"mobilenet\":\n",
    "    base_model = MobileNet(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3))\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"xception\":\n",
    "    base_model = Xception(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
    "    image_size = (299, 299)\n",
    "else:\n",
    "    base_model = None\n",
    "print (\"[INFO] successfully loaded base model and model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRadius(img):\n",
    "#     print(type(img.shape))\n",
    "    circles = cv2.HoughCircles(img,3,1,max(img.shape)/2,param1=50,param2=30,minRadius= int(max(img.shape)/6),maxRadius=max(img.shape))\n",
    "    return circles[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/'\n",
    "train_dir = original_dataset_dir+'dataset/train_images/'\n",
    "#read in table with image ids and retinopathy severity rating for associated image\n",
    "labels = pd.read_csv(original_dataset_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode retinopathy severity\n",
    "pd_diagnoses = pd.get_dummies(labels['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = keras.utils.to_categorical(labels['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_minus_diagnosis = labels.drop(columns = ['diagnosis'])\n",
    "dummy_labels = pd.concat([labels_minus_diagnosis,pd_diagnoses], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_labels=dummy_labels.set_index('id_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dummy_labels.transpose()\n",
    "t_dict = t.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_path = train_dir + '/sm'\n",
    "imgs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smudge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(train_dir):\n",
    "    if img.endswith('.png'):\n",
    "        img_array = cv2.imread(os.path.join(train_dir,img))\n",
    "        #crop each image to 80% of fundus diameter\n",
    "        try:\n",
    "            r = getRadius(img_array)\n",
    "            crop_r = round(r*0.8) \n",
    "        except:\n",
    "            crop_r = (img_array.shape[1]/2)*0.8\n",
    "            \n",
    "        center_x = int(img_array.shape[1]/2)\n",
    "        center_y = int(img_array.shape[0]/2)\n",
    "    \n",
    "        left_border = int(center_x - crop_r)\n",
    "        right_border = int(center_x + crop_r)\n",
    "        upper_border = int(center_y - crop_r)\n",
    "        lower_border = int(center_y + crop_r)\n",
    "    \n",
    "        if left_border < 0:\n",
    "            difference = 0- left_border\n",
    "            left_border = 0\n",
    "            right_border -=difference\n",
    "            upper_border += difference\n",
    "            lower_border -= difference\n",
    "        if upper_border < 0:\n",
    "            difference = 0- upper_border\n",
    "            upper_border = 0\n",
    "            lower_border -= difference\n",
    "            left_border += difference\n",
    "            right_border -= difference\n",
    "\n",
    "        cropped = img_array[upper_border:lower_border, left_border:right_border]\n",
    "        #resize image to resnet's expected input size\n",
    "        a = cv2.resize(cropped, (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "#         lab = cv2.cvtColor(a, cv2.COLOR_BGR2LAB)\n",
    "#         lab_planes = cv2.split(lab)\n",
    "#         clahe = cv2.createCLAHE(clipLimit= 1,tileGridSize=(round(a.shape[0]/6),round(a.shape[1]/6)))\n",
    "#         lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "#         lab = cv2.merge(lab_planes)\n",
    "#         a = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "       \n",
    "#         a =cv2.medianBlur(a,5)\n",
    "#         a=cv2.addWeighted(a, 4, cv2.GaussianBlur(a,(0,0), 30), -4, 128)\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        imgs[img[:-4]] = a\n",
    "        gc.collect()\n",
    "    \n",
    "#         os.chdir(sm_path)\n",
    "#         cv2.imwrite(\"sm\"+\"_\"+img ,a)\n",
    "#         os.chdir(path)   \n",
    "#     print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate arrays so that severity ratings have same order as their associated images\n",
    "ordered_imgs = []\n",
    "label_vectors = []\n",
    "for key in imgs.keys():\n",
    "    ordered_imgs.append(imgs[key])\n",
    "    lbls = []\n",
    "    for k in t_dict[key]:\n",
    "        lbls.append(t_dict[key][k])\n",
    "    label_vectors.append(lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 34s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19.output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_shape = vgg19.output_shape\n",
    "model = keras.models.Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(Dense(5,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = vgg19.output\n",
    "out = keras.layers.GlobalAveragePooling2D()(out)\n",
    "out = keras.layers.Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "total_classes = 5\n",
    "predictions = Dense(total_classes, activation='softmax')(out)\n",
    "\n",
    "model = keras.models.Model(inputs=vgg19.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "#instantiate pre-trained ResNet model\n",
    "res_fifty = keras.applications.ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x1d969ee80&gt;</td>\n",
       "      <td>input_6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da35a0f0&gt;</td>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da35ac50&gt;</td>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1da3a3b38&gt;</td>\n",
       "      <td>block1_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da388208&gt;</td>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da41c438&gt;</td>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1cf78f7f0&gt;</td>\n",
       "      <td>block2_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf78f7b8&gt;</td>\n",
       "      <td>block3_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6d8748&gt;</td>\n",
       "      <td>block3_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6cc1d0&gt;</td>\n",
       "      <td>block3_conv3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6dee48&gt;</td>\n",
       "      <td>block3_conv4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1cf6e5f60&gt;</td>\n",
       "      <td>block3_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6d5eb8&gt;</td>\n",
       "      <td>block4_conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6e7ef0&gt;</td>\n",
       "      <td>block4_conv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6e3710&gt;</td>\n",
       "      <td>block4_conv3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x191b5db70&gt;</td>\n",
       "      <td>block4_conv4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1c275fe48&gt;</td>\n",
       "      <td>block4_pool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6dc0f0&gt;</td>\n",
       "      <td>block5_conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1c26a1748&gt;</td>\n",
       "      <td>block5_conv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1c2550908&gt;</td>\n",
       "      <td>block5_conv3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6bda90&gt;</td>\n",
       "      <td>block5_conv4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1ccc2f4a8&gt;</td>\n",
       "      <td>block5_pool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x1aaf832e8&gt;</td>\n",
       "      <td>global_average_pooling2d_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Dense object at 0x1aaf83358&gt;</td>\n",
       "      <td>dense_7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;tensorflow.python.layers.core.Dense object at 0x1aaf83400&gt;</td>\n",
       "      <td>dense_9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;tensorflow.python.layers.core.Dense object at 0x201972f28&gt;</td>\n",
       "      <td>dense_10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               Layer Type  \\\n",
       "0   <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x1d969ee80>           \n",
       "1   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da35a0f0>             \n",
       "2   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da35ac50>             \n",
       "3   <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1da3a3b38>             \n",
       "4   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da388208>             \n",
       "5   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1da41c438>             \n",
       "6   <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1cf78f7f0>             \n",
       "7   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf78f7b8>             \n",
       "8   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6d8748>             \n",
       "9   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6cc1d0>             \n",
       "10  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6dee48>             \n",
       "11  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1cf6e5f60>             \n",
       "12  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6d5eb8>             \n",
       "13  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6e7ef0>             \n",
       "14  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6e3710>             \n",
       "15  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x191b5db70>             \n",
       "16  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1c275fe48>             \n",
       "17  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6dc0f0>             \n",
       "18  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1c26a1748>             \n",
       "19  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1c2550908>             \n",
       "20  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1cf6bda90>             \n",
       "21  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1ccc2f4a8>             \n",
       "22  <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x1aaf832e8>   \n",
       "23  <tensorflow.python.keras.layers.core.Dense object at 0x1aaf83358>                       \n",
       "24  <tensorflow.python.layers.core.Dense object at 0x1aaf83400>                             \n",
       "25  <tensorflow.python.layers.core.Dense object at 0x201972f28>                             \n",
       "\n",
       "                    Layer Name  Layer Trainable  \n",
       "0   input_6                     False            \n",
       "1   block1_conv1                False            \n",
       "2   block1_conv2                False            \n",
       "3   block1_pool                 False            \n",
       "4   block2_conv1                False            \n",
       "5   block2_conv2                False            \n",
       "6   block2_pool                 False            \n",
       "7   block3_conv1                False            \n",
       "8   block3_conv2                False            \n",
       "9   block3_conv3                False            \n",
       "10  block3_conv4                False            \n",
       "11  block3_pool                 False            \n",
       "12  block4_conv1                True             \n",
       "13  block4_conv2                True             \n",
       "14  block4_conv3                True             \n",
       "15  block4_conv4                True             \n",
       "16  block4_pool                 True             \n",
       "17  block5_conv1                True             \n",
       "18  block5_conv2                True             \n",
       "19  block5_conv3                True             \n",
       "20  block5_conv4                True             \n",
       "21  block5_pool                 True             \n",
       "22  global_average_pooling2d_1  True             \n",
       "23  dense_7                     True             \n",
       "24  dense_9                     True             \n",
       "25  dense_10                    True             "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "df_layers = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
    "df_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 175*0.8\n",
    "cnt = 0\n",
    "set_trainable = False\n",
    "for layer in vgg19.layers:\n",
    "    if 'block4' in layer.name:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "keras.utils.plot_model(res_fifty, to_file = 'res_fifty.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "184/184 [==============================] - 3090s 17s/step - loss: 8.1736\n",
      "Epoch 2/15\n",
      "184/184 [==============================] - 68943s 375s/step - loss: 8.1729\n",
      "Epoch 3/15\n",
      "184/184 [==============================] - 3196s 17s/step - loss: 8.1729\n",
      "Epoch 4/15\n",
      "184/184 [==============================] - 2988s 16s/step - loss: 8.1729\n",
      "Epoch 5/15\n",
      "184/184 [==============================] - 2942s 16s/step - loss: 8.1729\n",
      "Epoch 6/15\n",
      "184/184 [==============================] - 19444s 106s/step - loss: 8.1729\n",
      "Epoch 7/15\n",
      "184/184 [==============================] - 2856s 16s/step - loss: 8.1729\n",
      "Epoch 8/15\n",
      "184/184 [==============================] - 2805s 15s/step - loss: 8.1729\n",
      "Epoch 9/15\n",
      "184/184 [==============================] - 2781s 15s/step - loss: 8.1729\n",
      "Epoch 10/15\n",
      "184/184 [==============================] - 2780s 15s/step - loss: 8.1729\n",
      "Epoch 11/15\n",
      "184/184 [==============================] - 2779s 15s/step - loss: 8.1729\n",
      "Epoch 12/15\n",
      "184/184 [==============================] - 2772s 15s/step - loss: 8.1729\n",
      "Epoch 13/15\n",
      "184/184 [==============================] - 2773s 15s/step - loss: 8.1729\n",
      "Epoch 14/15\n",
      "184/184 [==============================] - 2792s 15s/step - loss: 8.1729\n",
      "Epoch 15/15\n",
      "184/184 [==============================] - 2764s 15s/step - loss: 8.1729\n"
     ]
    }
   ],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range = 180,horizontal_flip = True, vertical_flip = True, data_format = 'channels_last')\n",
    "batch_size = 20\n",
    "# datagen.fit(ordered_imgs)\n",
    " \n",
    "train_generator = datagen.flow(\n",
    "    np.asarray(ordered_imgs),\n",
    "    label_vectors,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False)\n",
    "\n",
    "train_steps_per_epoch = len(ordered_imgs) // batch_size\n",
    "model.compile('Adam', loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.savefig('loss_20190824')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block5_pool/MaxPool:0' shape=(?, ?, ?, 512) dtype=float32>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[21].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "get_last_pretrained_layer = keras.backend.function([model.layers[0].input, keras.backend.learning_phase()],\n",
    "                                  [model.layers[21].output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7, 7, 512)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_pretrained_layer(np.asarray(ordered_imgs[0:3]))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordered_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(len(ordered_imgs), 7, 7, 512))\n",
    "train_labels = np.zeros(shape=(len(ordered_imgs),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "False\n",
      "40\n",
      "False\n",
      "60\n",
      "False\n",
      "80\n",
      "False\n",
      "100\n",
      "False\n",
      "120\n",
      "False\n",
      "140\n",
      "False\n",
      "160\n",
      "False\n",
      "180\n",
      "False\n",
      "200\n",
      "False\n",
      "220\n",
      "False\n",
      "240\n",
      "False\n",
      "260\n",
      "False\n",
      "280\n",
      "False\n",
      "300\n",
      "False\n",
      "320\n",
      "False\n",
      "340\n",
      "False\n",
      "360\n",
      "False\n",
      "380\n",
      "False\n",
      "400\n",
      "False\n",
      "420\n",
      "False\n",
      "440\n",
      "False\n",
      "460\n",
      "False\n",
      "480\n",
      "False\n",
      "500\n",
      "False\n",
      "520\n",
      "False\n",
      "540\n",
      "False\n",
      "560\n",
      "False\n",
      "580\n",
      "False\n",
      "600\n",
      "False\n",
      "620\n",
      "False\n",
      "640\n",
      "False\n",
      "660\n",
      "False\n",
      "680\n",
      "False\n",
      "700\n",
      "False\n",
      "720\n",
      "False\n",
      "740\n",
      "False\n",
      "760\n",
      "False\n",
      "780\n",
      "False\n",
      "800\n",
      "False\n",
      "820\n",
      "False\n",
      "840\n",
      "False\n",
      "860\n",
      "False\n",
      "880\n",
      "False\n",
      "882\n",
      "False\n",
      "902\n",
      "False\n",
      "922\n",
      "False\n",
      "942\n",
      "False\n",
      "962\n",
      "False\n",
      "982\n",
      "False\n",
      "1002\n",
      "False\n",
      "1022\n",
      "False\n",
      "1042\n",
      "False\n",
      "1062\n",
      "False\n",
      "1082\n",
      "False\n",
      "1102\n",
      "False\n",
      "1122\n",
      "False\n",
      "1142\n",
      "False\n",
      "1162\n",
      "False\n",
      "1182\n",
      "False\n",
      "1202\n",
      "False\n",
      "1222\n",
      "False\n",
      "1242\n",
      "False\n",
      "1262\n",
      "False\n",
      "1282\n",
      "False\n",
      "1302\n",
      "False\n",
      "1322\n",
      "False\n",
      "1342\n",
      "False\n",
      "1362\n",
      "False\n",
      "1382\n",
      "False\n",
      "1402\n",
      "False\n",
      "1422\n",
      "False\n",
      "1442\n",
      "False\n",
      "1462\n",
      "False\n",
      "1482\n",
      "False\n",
      "1502\n",
      "False\n",
      "1522\n",
      "False\n",
      "1542\n",
      "False\n",
      "1562\n",
      "False\n",
      "1582\n",
      "False\n",
      "1602\n",
      "False\n",
      "1622\n",
      "False\n",
      "1642\n",
      "False\n",
      "1662\n",
      "False\n",
      "1682\n",
      "False\n",
      "1702\n",
      "False\n",
      "1722\n",
      "False\n",
      "1742\n",
      "False\n",
      "1762\n",
      "False\n",
      "1782\n",
      "False\n",
      "1802\n",
      "False\n",
      "1822\n",
      "False\n",
      "1842\n",
      "False\n",
      "1862\n",
      "False\n",
      "1882\n",
      "False\n",
      "1902\n",
      "False\n",
      "1922\n",
      "False\n",
      "1942\n",
      "False\n",
      "1962\n",
      "False\n",
      "1982\n",
      "False\n",
      "2002\n",
      "False\n",
      "2022\n",
      "False\n",
      "2042\n",
      "False\n",
      "2062\n",
      "False\n",
      "2082\n",
      "False\n",
      "2102\n",
      "False\n",
      "2122\n",
      "False\n",
      "2142\n",
      "False\n",
      "2162\n",
      "False\n",
      "2182\n",
      "False\n",
      "2202\n",
      "False\n",
      "2222\n",
      "False\n",
      "2242\n",
      "False\n",
      "2262\n",
      "False\n",
      "2282\n",
      "False\n",
      "2302\n",
      "False\n",
      "2322\n",
      "False\n",
      "2342\n",
      "False\n",
      "2362\n",
      "False\n",
      "2382\n",
      "False\n",
      "2402\n",
      "False\n",
      "2422\n",
      "False\n",
      "2442\n",
      "False\n",
      "2462\n",
      "False\n",
      "2482\n",
      "False\n",
      "2502\n",
      "False\n",
      "2522\n",
      "False\n",
      "2542\n",
      "False\n",
      "2562\n",
      "False\n",
      "2582\n",
      "False\n",
      "2602\n",
      "False\n",
      "2622\n",
      "False\n",
      "2642\n",
      "False\n",
      "2662\n",
      "False\n",
      "2682\n",
      "False\n",
      "2702\n",
      "False\n",
      "2722\n",
      "False\n",
      "2742\n",
      "False\n",
      "2762\n",
      "False\n",
      "2782\n",
      "False\n",
      "2802\n",
      "False\n",
      "2822\n",
      "False\n",
      "2842\n",
      "False\n",
      "2862\n",
      "False\n",
      "2882\n",
      "False\n",
      "2902\n",
      "False\n",
      "2922\n",
      "False\n",
      "2942\n",
      "False\n",
      "2962\n",
      "False\n",
      "2982\n",
      "False\n",
      "3002\n",
      "False\n",
      "3022\n",
      "False\n",
      "3042\n",
      "False\n",
      "3062\n",
      "False\n",
      "3082\n",
      "False\n",
      "3102\n",
      "False\n",
      "3122\n",
      "False\n",
      "3142\n",
      "False\n",
      "3162\n",
      "False\n",
      "3182\n",
      "False\n",
      "3202\n",
      "False\n",
      "3222\n",
      "False\n",
      "3242\n",
      "False\n",
      "3262\n",
      "False\n",
      "3282\n",
      "False\n",
      "3302\n",
      "False\n",
      "3322\n",
      "False\n",
      "3342\n",
      "False\n",
      "3362\n",
      "False\n",
      "3382\n",
      "False\n",
      "3402\n",
      "False\n",
      "3422\n",
      "False\n",
      "3442\n",
      "False\n",
      "3462\n",
      "False\n",
      "3482\n",
      "False\n",
      "3502\n",
      "False\n",
      "3522\n",
      "False\n",
      "3542\n",
      "False\n",
      "3562\n",
      "False\n",
      "3582\n",
      "False\n",
      "3602\n",
      "False\n",
      "3622\n",
      "False\n",
      "3642\n",
      "False\n",
      "3662\n",
      "False\n",
      "beep\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = get_last_pretrained_layer(inputs_batch)[0]\n",
    "    train_features[i : i + len(inputs_batch)] = features_batch \n",
    "    train_labels[i : i +len(inputs_batch)] = labels_batch\n",
    "    i+= len(inputs_batch)\n",
    "    print(i)\n",
    "    print(i>len(ordered_imgs))\n",
    "    if i+len(inputs_batch) > len(ordered_imgs):\n",
    "        print('beep')\n",
    "        break\n",
    "# train_features = np.reshape(train_features, (len(ordered_imgs), 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (len(ordered_imgs), 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(train_features.shape[0], len(ordered_imgs)//5, replace=False)\n",
    "features = train_features[indices, :]\n",
    "tlabels = train_labels[indices,:]\n",
    "i,j = np.where(train_labels==1)\n",
    "t_labels = j[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputCodeClassifier(code_size=1.5,\n",
       "           estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=69,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=None, random_state=420)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OutputCodeClassifier as occ\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(train_features,j,test_size = 0.1)\n",
    "clf = occ(SVC(random_state=69), random_state= 420)\n",
    "clf.fit(features_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.random.choice(train_features.shape[0], len(ordered_imgs)//10, replace=False)\n",
    "test_features = train_features[test_indices, :]\n",
    "test_labels = j[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ouput = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204359673024523"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "occ produces 0.63 accuracy w/ 3662//5 train images, frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
