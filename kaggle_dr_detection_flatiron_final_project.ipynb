{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.layers import Dense\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2019-08-22 13:06\n",
      "WARNING:tensorflow:From /Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] successfully loaded base model and model...\n"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# keras imports\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "# from keras.applications.xception import Xception, preprocess_input\n",
    "# from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "# from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from keras.preprocessing import image\n",
    "# from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "# load the user configs\n",
    "with open('conf/conf.json') as f:    \n",
    "    config = json.load(f)\n",
    "# config variables\n",
    "model_name = config[\"model\"]\n",
    "weights = config[\"weights\"]\n",
    "include_top = config[\"include_top\"]\n",
    "train_path = config[\"train_path\"]\n",
    "features_path = config[\"features_path\"]\n",
    "labels_path = config[\"labels_path\"]\n",
    "test_size = config[\"test_size\"]\n",
    "results = config[\"results\"]\n",
    "model_path = config[\"model_path\"]\n",
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "    base_model = VGG19(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "    base_model = keras.applications.ResNet50(include_top=False, weights=weights)\n",
    "    model = base_model\n",
    "#     model = Model(input=base_model.input, output=base_model.layers[-1].output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "    base_model = InceptionV3(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"inceptionresnetv2\":\n",
    "    base_model = InceptionResNetV2(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "#     model = Model(input=base_model.input, output=base_model.layers[-1].output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"mobilenet\":\n",
    "    base_model = MobileNet(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3))\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"xception\":\n",
    "    base_model = Xception(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
    "    image_size = (299, 299)\n",
    "else:\n",
    "    base_model = None\n",
    "print (\"[INFO] successfully loaded base model and model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRadius(img):\n",
    "#     print(type(img.shape))\n",
    "    circles = cv2.HoughCircles(img,3,1,max(img.shape)/2,param1=50,param2=30,minRadius= int(max(img.shape)/6),maxRadius=max(img.shape))\n",
    "    return circles[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = '/Users/flatironschool/Documents/Kaggle/Kaggle-DR-detection/'\n",
    "train_dir = original_dataset_dir+'dataset/train_images/'\n",
    "#read in table with image ids and retinopathy severity rating for associated image\n",
    "labels = pd.read_csv(original_dataset_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode retinopathy severity\n",
    "pd_diagnoses = pd.get_dummies(labels['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = keras.utils.to_categorical(labels['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_minus_diagnosis = labels.drop(columns = ['diagnosis'])\n",
    "dummy_labels = pd.concat([labels_minus_diagnosis,pd_diagnoses], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_labels=dummy_labels.set_index('id_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dummy_labels.transpose()\n",
    "t_dict = t.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_path = train_dir + '/sm'\n",
    "imgs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smudge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(train_dir):\n",
    "    if img.endswith('.png'):\n",
    "        img_array = cv2.imread(os.path.join(train_dir,img))\n",
    "        #crop each image to 80% of fundus diameter\n",
    "        try:\n",
    "            r = getRadius(img_array)\n",
    "            crop_r = round(r*0.8) \n",
    "        except:\n",
    "            crop_r = (img_array.shape[1]/2)*0.8\n",
    "            \n",
    "        center_x = int(img_array.shape[1]/2)\n",
    "        center_y = int(img_array.shape[0]/2)\n",
    "    \n",
    "        left_border = int(center_x - crop_r)\n",
    "        right_border = int(center_x + crop_r)\n",
    "        upper_border = int(center_y - crop_r)\n",
    "        lower_border = int(center_y + crop_r)\n",
    "    \n",
    "        if left_border < 0:\n",
    "            difference = 0- left_border\n",
    "            left_border = 0\n",
    "            right_border -=difference\n",
    "            upper_border += difference\n",
    "            lower_border -= difference\n",
    "        if upper_border < 0:\n",
    "            difference = 0- upper_border\n",
    "            upper_border = 0\n",
    "            lower_border -= difference\n",
    "            left_border += difference\n",
    "            right_border -= difference\n",
    "\n",
    "        cropped = img_array[upper_border:lower_border, left_border:right_border]\n",
    "        #resize image to resnet's expected input size\n",
    "        a = cv2.resize(cropped, (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "#         lab = cv2.cvtColor(a, cv2.COLOR_BGR2LAB)\n",
    "#         lab_planes = cv2.split(lab)\n",
    "#         clahe = cv2.createCLAHE(clipLimit= 1,tileGridSize=(round(a.shape[0]/6),round(a.shape[1]/6)))\n",
    "#         lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "#         lab = cv2.merge(lab_planes)\n",
    "#         a = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "       \n",
    "#         a =cv2.medianBlur(a,5)\n",
    "#         a=cv2.addWeighted(a, 4, cv2.GaussianBlur(a,(0,0), 30), -4, 128)\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        imgs[img[:-4]] = a\n",
    "        gc.collect()\n",
    "    \n",
    "#         os.chdir(sm_path)\n",
    "#         cv2.imwrite(\"sm\"+\"_\"+img ,a)\n",
    "#         os.chdir(path)   \n",
    "#     print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate arrays so that severity ratings have same order as their associated images\n",
    "ordered_imgs = []\n",
    "label_vectors = []\n",
    "for key in imgs.keys():\n",
    "    ordered_imgs.append(imgs[key])\n",
    "    lbls = []\n",
    "    for k in t_dict[key]:\n",
    "        lbls.append(t_dict[key][k])\n",
    "    label_vectors.append(lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "#instantiate pre-trained ResNet model\n",
    "res_fifty = keras.applications.ResNet50(include_top=False, weights='imagenet')\n",
    "# for layer in res_fifty.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x10c5f1a90&gt;</td>\n",
       "      <td>input_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x15701dac8&gt;</td>\n",
       "      <td>conv1_pad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x15701df98&gt;</td>\n",
       "      <td>conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15701def0&gt;</td>\n",
       "      <td>bn_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x15701deb8&gt;</td>\n",
       "      <td>activation_98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x157060eb8&gt;</td>\n",
       "      <td>pool1_pad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x157060a58&gt;</td>\n",
       "      <td>max_pooling2d_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x156fb5fd0&gt;</td>\n",
       "      <td>res2a_branch2a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1568656a0&gt;</td>\n",
       "      <td>bn2a_branch2a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x156865b38&gt;</td>\n",
       "      <td>activation_99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1568825c0&gt;</td>\n",
       "      <td>res2a_branch2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x156892710&gt;</td>\n",
       "      <td>bn2a_branch2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x156892b38&gt;</td>\n",
       "      <td>activation_100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x156941e10&gt;</td>\n",
       "      <td>res2a_branch2c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x155407048&gt;</td>\n",
       "      <td>res2a_branch1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15695a0b8&gt;</td>\n",
       "      <td>bn2a_branch2c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x155420978&gt;</td>\n",
       "      <td>bn2a_branch1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x155420cc0&gt;</td>\n",
       "      <td>add_32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x1554e4b38&gt;</td>\n",
       "      <td>activation_101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554e49b0&gt;</td>\n",
       "      <td>res2b_branch2a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15551e208&gt;</td>\n",
       "      <td>bn2b_branch2a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x155582cc0&gt;</td>\n",
       "      <td>activation_102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1555cb5c0&gt;</td>\n",
       "      <td>res2b_branch2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1555dd780&gt;</td>\n",
       "      <td>bn2b_branch2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x1555ddba8&gt;</td>\n",
       "      <td>activation_103</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x155689d68&gt;</td>\n",
       "      <td>res2b_branch2c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1556a3828&gt;</td>\n",
       "      <td>bn2b_branch2c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x1556c3048&gt;</td>\n",
       "      <td>add_33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x1569af668&gt;</td>\n",
       "      <td>activation_104</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1569afeb8&gt;</td>\n",
       "      <td>res2c_branch2a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c2a4be0&gt;</td>\n",
       "      <td>activation_138</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c2c6a58&gt;</td>\n",
       "      <td>res5a_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c2daeb8&gt;</td>\n",
       "      <td>bn5a_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c2dacc0&gt;</td>\n",
       "      <td>activation_139</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c3a62b0&gt;</td>\n",
       "      <td>res5a_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c3c06d8&gt;</td>\n",
       "      <td>res5a_branch1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c3a6240&gt;</td>\n",
       "      <td>bn5a_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c47ee48&gt;</td>\n",
       "      <td>bn5a_branch1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x17c47e550&gt;</td>\n",
       "      <td>add_45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c547f28&gt;</td>\n",
       "      <td>activation_140</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c547ef0&gt;</td>\n",
       "      <td>res5b_branch2a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c580a90&gt;</td>\n",
       "      <td>bn5b_branch2a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c601dd8&gt;</td>\n",
       "      <td>activation_141</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c6486d8&gt;</td>\n",
       "      <td>res5b_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c65cba8&gt;</td>\n",
       "      <td>bn5b_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c65ccc0&gt;</td>\n",
       "      <td>activation_142</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c708f98&gt;</td>\n",
       "      <td>res5b_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c723e48&gt;</td>\n",
       "      <td>bn5b_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x17c73e6d8&gt;</td>\n",
       "      <td>add_46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c7ea898&gt;</td>\n",
       "      <td>activation_143</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c7ea860&gt;</td>\n",
       "      <td>res5c_branch2a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c8621d0&gt;</td>\n",
       "      <td>bn5c_branch2a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c8e2748&gt;</td>\n",
       "      <td>activation_144</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c926f98&gt;</td>\n",
       "      <td>res5c_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c926ef0&gt;</td>\n",
       "      <td>bn5c_branch2b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17c97cc50&gt;</td>\n",
       "      <td>activation_145</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c9ea9b0&gt;</td>\n",
       "      <td>res5c_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17ca04e10&gt;</td>\n",
       "      <td>bn5c_branch2c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x17ca04c18&gt;</td>\n",
       "      <td>add_47</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x17cacc208&gt;</td>\n",
       "      <td>activation_146</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    Layer Type  \\\n",
       "0    <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x10c5f1a90>               \n",
       "1    <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x15701dac8>          \n",
       "2    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x15701df98>                 \n",
       "3    <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15701def0>   \n",
       "4    <tensorflow.python.keras.layers.core.Activation object at 0x15701deb8>                      \n",
       "5    <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x157060eb8>          \n",
       "6    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x157060a58>                 \n",
       "7    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x156fb5fd0>                 \n",
       "8    <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1568656a0>   \n",
       "9    <tensorflow.python.keras.layers.core.Activation object at 0x156865b38>                      \n",
       "10   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1568825c0>                 \n",
       "11   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x156892710>   \n",
       "12   <tensorflow.python.keras.layers.core.Activation object at 0x156892b38>                      \n",
       "13   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x156941e10>                 \n",
       "14   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x155407048>                 \n",
       "15   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15695a0b8>   \n",
       "16   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x155420978>   \n",
       "17   <tensorflow.python.keras.layers.merge.Add object at 0x155420cc0>                            \n",
       "18   <tensorflow.python.keras.layers.core.Activation object at 0x1554e4b38>                      \n",
       "19   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554e49b0>                 \n",
       "20   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x15551e208>   \n",
       "21   <tensorflow.python.keras.layers.core.Activation object at 0x155582cc0>                      \n",
       "22   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1555cb5c0>                 \n",
       "23   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1555dd780>   \n",
       "24   <tensorflow.python.keras.layers.core.Activation object at 0x1555ddba8>                      \n",
       "25   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x155689d68>                 \n",
       "26   <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x1556a3828>   \n",
       "27   <tensorflow.python.keras.layers.merge.Add object at 0x1556c3048>                            \n",
       "28   <tensorflow.python.keras.layers.core.Activation object at 0x1569af668>                      \n",
       "29   <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1569afeb8>                 \n",
       "..                                                                           ...                 \n",
       "145  <tensorflow.python.keras.layers.core.Activation object at 0x17c2a4be0>                      \n",
       "146  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c2c6a58>                 \n",
       "147  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c2daeb8>   \n",
       "148  <tensorflow.python.keras.layers.core.Activation object at 0x17c2dacc0>                      \n",
       "149  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c3a62b0>                 \n",
       "150  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c3c06d8>                 \n",
       "151  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c3a6240>   \n",
       "152  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c47ee48>   \n",
       "153  <tensorflow.python.keras.layers.merge.Add object at 0x17c47e550>                            \n",
       "154  <tensorflow.python.keras.layers.core.Activation object at 0x17c547f28>                      \n",
       "155  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c547ef0>                 \n",
       "156  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c580a90>   \n",
       "157  <tensorflow.python.keras.layers.core.Activation object at 0x17c601dd8>                      \n",
       "158  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c6486d8>                 \n",
       "159  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c65cba8>   \n",
       "160  <tensorflow.python.keras.layers.core.Activation object at 0x17c65ccc0>                      \n",
       "161  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c708f98>                 \n",
       "162  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c723e48>   \n",
       "163  <tensorflow.python.keras.layers.merge.Add object at 0x17c73e6d8>                            \n",
       "164  <tensorflow.python.keras.layers.core.Activation object at 0x17c7ea898>                      \n",
       "165  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c7ea860>                 \n",
       "166  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c8621d0>   \n",
       "167  <tensorflow.python.keras.layers.core.Activation object at 0x17c8e2748>                      \n",
       "168  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c926f98>                 \n",
       "169  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17c926ef0>   \n",
       "170  <tensorflow.python.keras.layers.core.Activation object at 0x17c97cc50>                      \n",
       "171  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x17c9ea9b0>                 \n",
       "172  <tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x17ca04e10>   \n",
       "173  <tensorflow.python.keras.layers.merge.Add object at 0x17ca04c18>                            \n",
       "174  <tensorflow.python.keras.layers.core.Activation object at 0x17cacc208>                      \n",
       "\n",
       "          Layer Name  Layer Trainable  \n",
       "0    input_3          False            \n",
       "1    conv1_pad        False            \n",
       "2    conv1            False            \n",
       "3    bn_conv1         False            \n",
       "4    activation_98    False            \n",
       "5    pool1_pad        False            \n",
       "6    max_pooling2d_2  False            \n",
       "7    res2a_branch2a   False            \n",
       "8    bn2a_branch2a    False            \n",
       "9    activation_99    False            \n",
       "10   res2a_branch2b   False            \n",
       "11   bn2a_branch2b    False            \n",
       "12   activation_100   False            \n",
       "13   res2a_branch2c   False            \n",
       "14   res2a_branch1    False            \n",
       "15   bn2a_branch2c    False            \n",
       "16   bn2a_branch1     False            \n",
       "17   add_32           False            \n",
       "18   activation_101   False            \n",
       "19   res2b_branch2a   False            \n",
       "20   bn2b_branch2a    False            \n",
       "21   activation_102   False            \n",
       "22   res2b_branch2b   False            \n",
       "23   bn2b_branch2b    False            \n",
       "24   activation_103   False            \n",
       "25   res2b_branch2c   False            \n",
       "26   bn2b_branch2c    False            \n",
       "27   add_33           False            \n",
       "28   activation_104   False            \n",
       "29   res2c_branch2a   False            \n",
       "..              ...     ...            \n",
       "145  activation_138   True             \n",
       "146  res5a_branch2b   True             \n",
       "147  bn5a_branch2b    True             \n",
       "148  activation_139   True             \n",
       "149  res5a_branch2c   True             \n",
       "150  res5a_branch1    True             \n",
       "151  bn5a_branch2c    True             \n",
       "152  bn5a_branch1     True             \n",
       "153  add_45           True             \n",
       "154  activation_140   True             \n",
       "155  res5b_branch2a   True             \n",
       "156  bn5b_branch2a    True             \n",
       "157  activation_141   True             \n",
       "158  res5b_branch2b   True             \n",
       "159  bn5b_branch2b    True             \n",
       "160  activation_142   True             \n",
       "161  res5b_branch2c   True             \n",
       "162  bn5b_branch2c    True             \n",
       "163  add_46           True             \n",
       "164  activation_143   True             \n",
       "165  res5c_branch2a   True             \n",
       "166  bn5c_branch2a    True             \n",
       "167  activation_144   True             \n",
       "168  res5c_branch2b   True             \n",
       "169  bn5c_branch2b    True             \n",
       "170  activation_145   True             \n",
       "171  res5c_branch2c   True             \n",
       "172  bn5c_branch2c    True             \n",
       "173  add_47           True             \n",
       "174  activation_146   True             \n",
       "\n",
       "[175 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in res_fifty.layers]\n",
    "df_layers = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
    "df_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 175*0.8\n",
    "cnt = 0\n",
    "set_trainable = False\n",
    "for layer in res_fifty.layers:\n",
    "    if cnt > p:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [20,5] vs. [20,7,7,2048]\n\t [[{{node training/Adam/gradients/loss/activation_48_loss/mul_grad/BroadcastGradientArgs}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-b58656000405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m history = model.fit_generator(train_generator,\n\u001b[1;32m     14\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                               epochs=15, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [20,5] vs. [20,7,7,2048]\n\t [[{{node training/Adam/gradients/loss/activation_48_loss/mul_grad/BroadcastGradientArgs}}]]"
     ]
    }
   ],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range = 180,horizontal_flip = True, vertical_flip = True,data_format = 'channels_last')\n",
    "batch_size = 20\n",
    "# datagen.fit(ordered_imgs)\n",
    " \n",
    "train_generator = datagen.flow(\n",
    "    np.asarray(ordered_imgs),\n",
    "    label_vectors,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False)\n",
    "\n",
    "train_steps_per_epoch = len(ordered_imgs) // batch_size\n",
    "model.compile(keras.optimizers.Adam(lr = 0.0001), loss = 'categorical_crossentropy')\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m(533)\u001b[0;36m__exit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    530 \u001b[0;31m    \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    531 \u001b[0;31m    \u001b[0;31m# raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    532 \u001b[0;31m    \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 533 \u001b[0;31m      \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    534 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# False values do not suppress exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m(1445)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1443 \u001b[0;31m      \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1444 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1445 \u001b[0;31m          \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1446 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1447 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m(3076)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   3074 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3075 \u001b[0;31m    fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0m\u001b[0;32m-> 3076 \u001b[0;31m                                run_metadata=self.run_metadata)\n",
      "\u001b[0m\u001b[0;32m   3077 \u001b[0;31m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3078 \u001b[0;31m    return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m(1191)\u001b[0;36mtrain_on_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1189 \u001b[0;31m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1190 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1191 \u001b[0;31m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1192 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1193 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m(191)\u001b[0;36mmodel_iteration\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    189 \u001b[0;31m      \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 191 \u001b[0;31m      \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    192 \u001b[0;31m      \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    193 \u001b[0;31m        \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m(1426)\u001b[0;36mfit_generator\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1424 \u001b[0;31m        \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1425 \u001b[0;31m        \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1426 \u001b[0;31m        initial_epoch=initial_epoch)\n",
      "\u001b[0m\u001b[0;32m   1427 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1428 \u001b[0;31m  def evaluate_generator(self,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-72-b58656000405>\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m\u001b[0mtrain_steps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_imgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31mhistory = model.fit_generator(train_generator,\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m                              \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m                              epochs=15, verbose=1)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Oldest frame\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m(1426)\u001b[0;36mfit_generator\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1424 \u001b[0;31m        \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1425 \u001b[0;31m        \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1426 \u001b[0;31m        initial_epoch=initial_epoch)\n",
      "\u001b[0m\u001b[0;32m   1427 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1428 \u001b[0;31m  def evaluate_generator(self,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/flatironschool/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m(191)\u001b[0;36mmodel_iteration\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    189 \u001b[0;31m      \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 191 \u001b[0;31m      \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    192 \u001b[0;31m      \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    193 \u001b[0;31m        \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(batch_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(batch_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch_data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[[ 59.521267 ,  49.7819   ,  41.303165 ],\n",
      "         [ 61.23142  ,  49.743805 ,  41.11571  ],\n",
      "         [ 64.99556  ,  51.01332  ,  43.00888  ],\n",
      "         ...,\n",
      "         [185.89722  , 101.19628  ,  73.046745 ],\n",
      "         [169.60521  ,  79.70688  ,  59.404266 ],\n",
      "         [165.84576  ,  76.69152  ,  56.84576  ]],\n",
      "\n",
      "        [[ 61.10549  ,  52.070328 ,  44.964836 ],\n",
      "         [ 59.805256 ,  50.207882 ,  42.013134 ],\n",
      "         [ 60.37946  ,  49.45982  ,  40.689728 ],\n",
      "         ...,\n",
      "         [172.72908  ,  83.82469  ,  61.960155 ],\n",
      "         [164.9938   ,  74.987595 ,  55.993797 ],\n",
      "         [167.82487  ,  83.53415  ,  60.32049  ]],\n",
      "\n",
      "        [[ 63.42908  ,  53.61939  ,  44.190308 ],\n",
      "         [ 61.53147  ,  52.354317 ,  44.82284  ],\n",
      "         [ 60.08924  ,  50.63386  ,  42.723103 ],\n",
      "         ...,\n",
      "         [164.14183  ,  73.28367  ,  55.141834 ],\n",
      "         [168.78902  ,  82.57803  ,  59.789017 ],\n",
      "         [160.86697  ,  86.69683  ,  62.2181   ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 38.54462  ,  37.54462  ,  33.54462  ],\n",
      "         [ 38.3617   ,  37.3617   ,  34.       ],\n",
      "         [ 37.187363 ,  36.187363 ,  34.       ],\n",
      "         ...,\n",
      "         [ 38.       ,  29.28249  ,  27.28249  ],\n",
      "         [ 38.       ,  28.017416 ,  26.017416 ],\n",
      "         [ 39.871487 ,  30.495314 ,  26.       ]],\n",
      "\n",
      "        [[ 38.645683 ,  37.645683 ,  34.       ],\n",
      "         [ 37.096622 ,  36.096622 ,  34.       ],\n",
      "         [ 38.45244  ,  37.45244  ,  34.       ],\n",
      "         ...,\n",
      "         [ 37.16845  ,  29.16845  ,  26.752674 ],\n",
      "         [ 38.       ,  29.566477 ,  27.566477 ],\n",
      "         [ 38.       ,  28.301405 ,  26.301405 ]],\n",
      "\n",
      "        [[ 37.38061  ,  36.38061  ,  34.       ],\n",
      "         [ 38.16845  ,  37.16845  ,  34.       ],\n",
      "         [ 40.076263 ,  39.076263 ,  35.076263 ],\n",
      "         ...,\n",
      "         [ 36.57092  ,  28.380611 ,  24.809694 ],\n",
      "         [ 36.88446  ,  28.884462 ,  26.326693 ],\n",
      "         [ 38.       ,  29.850466 ,  27.850466 ]]],\n",
      "\n",
      "\n",
      "       [[[ 96.12883  ,  51.613503 ,  16.355835 ],\n",
      "         [ 91.50264  ,  50.07256  ,  14.430079 ],\n",
      "         [ 91.06897  ,  49.41379  ,  13.827587 ],\n",
      "         ...,\n",
      "         [130.       ,  81.       ,  22.       ],\n",
      "         [130.       ,  81.       ,  22.       ],\n",
      "         [130.65707  ,  81.32854  ,  21.67146  ]],\n",
      "\n",
      "        [[ 96.76529  ,  49.704132 ,  13.173556 ],\n",
      "         [ 95.95783  ,  51.981926 ,  16.975903 ],\n",
      "         [ 90.55864  ,  49.667988 ,  13.89065  ],\n",
      "         ...,\n",
      "         [130.       ,  81.       ,  22.       ],\n",
      "         [130.9268   ,  81.4634   ,  21.536602 ],\n",
      "         [131.60059  ,  82.       ,  20.900146 ]],\n",
      "\n",
      "        [[ 97.40174  ,  49.401745 ,  12.803489 ],\n",
      "         [ 96.63043  ,  50.108707 ,  13.847843 ],\n",
      "         [ 95.013824 ,  51.577354 ,  16.436472 ],\n",
      "         ...,\n",
      "         [131.19652  ,  81.59826  ,  21.401745 ],\n",
      "         [131.06116  ,  82.       ,  20.76529  ],\n",
      "         [128.51534  ,  82.       ,  20.128834 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[136.43648  ,  79.43647  ,  19.295591 ],\n",
      "         [135.51328  ,  79.00885  ,  19.504427 ],\n",
      "         [133.60391  ,  78.39609  ,  19.13203  ],\n",
      "         ...,\n",
      "         [140.65068  , 125.65069  ,  42.65069  ],\n",
      "         [140.89194  , 125.89194  ,  42.       ],\n",
      "         [141.56543  , 126.56544  ,  41.565434 ]],\n",
      "\n",
      "        [[135.1087   ,  78.739136 ,  19.369568 ],\n",
      "         [133.19934  ,  78.80066  ,  19.266888 ],\n",
      "         [131.28998  ,  80.71003  ,  19.903343 ],\n",
      "         ...,\n",
      "         [141.9236   , 126.9236   ,  43.9236   ],\n",
      "         [140.38097  , 125.380974 ,  42.380974 ],\n",
      "         [141.16165  , 126.16165  ,  42.       ]],\n",
      "\n",
      "        [[132.79477  ,  79.20523  ,  19.401745 ],\n",
      "         [130.9618   ,  80.8854   ,  19.9236   ],\n",
      "         [130.32535  ,  78.97603  ,  18.650688 ],\n",
      "         ...,\n",
      "         [138.41046  , 125.20523  ,  42.80349  ],\n",
      "         [141.65388  , 126.653885 ,  43.653885 ],\n",
      "         [140.11125  , 125.11126  ,  42.11126  ]]],\n",
      "\n",
      "\n",
      "       [[[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[160.36551  ,  88.36552  ,   6.1117206],\n",
      "         [157.1587   ,  85.158714 ,   1.6221961],\n",
      "         [156.40962  ,  84.409615 ,   0.8192367],\n",
      "         ...,\n",
      "         [166.12598  ,  87.502785 ,   9.250835 ],\n",
      "         [170.85428  ,  91.92714  ,  15.781409 ],\n",
      "         [170.9519   ,  91.36153  ,  19.409618 ]],\n",
      "\n",
      "        [[157.7983   ,  85.79829  ,   3.7982876],\n",
      "         [160.9949   ,  88.99491  ,   6.9928727],\n",
      "         [157.7881   ,  85.78811  ,   2.5033484],\n",
      "         ...,\n",
      "         [170.099    ,  91.5495   ,  14.6484995],\n",
      "         [171.5813   ,  91.86504  ,  19.28374  ],\n",
      "         [167.94902  ,  89.05098  ,  20.152937 ]],\n",
      "\n",
      "        [[156.40758  ,  84.407585 ,   2.407582 ],\n",
      "         [157.1689   ,  85.16889  ,   3.168893 ],\n",
      "         [160.3757   ,  88.375694 ,   6.375696 ],\n",
      "         ...,\n",
      "         [172.2107   ,  92.36856  ,  19.15786  ],\n",
      "         [168.3745   ,  89.2996   ,  19.9251   ],\n",
      "         [167.30766  ,  89.69234  ,  22.077019 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[155.1118   ,  86.11181  ,  20.       ],\n",
      "         [156.64629  ,  87.646286 ,  20.       ],\n",
      "         [155.81923  ,  88.       ,  12.915421 ],\n",
      "         ...,\n",
      "         [152.84637  ,  86.846375 ,  10.384679 ],\n",
      "         [148.35686  ,  82.35685  ,   9.101958 ],\n",
      "         [150.36153  ,  83.77115  ,  12.54229  ]],\n",
      "\n",
      "        [[156.39453  ,  87.39452  ,  20.       ],\n",
      "         [156.071    ,  88.       ,  14.425967 ],\n",
      "         [156.6222   ,  89.62219  ,   7.536515 ],\n",
      "         ...,\n",
      "         [150.86378  ,  85.323364 ,   6.404208 ],\n",
      "         [153.72752  ,  87.72753  ,  10.636437 ],\n",
      "         [149.238    ,  83.23801  ,   9.353716 ]],\n",
      "\n",
      "        [[156.32275  ,  88.       ,  15.936514 ],\n",
      "         [155.74104  ,  88.74104  ,   7.7882733],\n",
      "         [161.11172  ,  94.11172  ,   6.253794 ],\n",
      "         ...,\n",
      "         [145.77318  ,  81.       ,   2.81455  ],\n",
      "         [149.73088  ,  84.31634  ,   5.145419 ],\n",
      "         [154.60869  ,  88.60868  ,  10.888195 ]]],\n",
      "\n",
      "\n",
      "       [[[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]],\n",
      "\n",
      "        [[  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         ...,\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ],\n",
      "         [  0.       ,   0.       ,   0.       ]]],\n",
      "\n",
      "\n",
      "       [[[ 88.30099  ,  81.       ,  50.150494 ],\n",
      "         [ 88.14036  ,  81.30576  ,  49.305767 ],\n",
      "         [ 92.06611  ,  82.186775 ,  50.373558 ],\n",
      "         ...,\n",
      "         [ 52.       ,  45.57525  ,  34.42475  ],\n",
      "         [ 52.       ,  45.102154 ,  34.897846 ],\n",
      "         [ 53.112812 ,  45.741875 ,  35.370937 ]],\n",
      "\n",
      "        [[ 90.09668  ,  81.04834  ,  51.14502  ],\n",
      "         [ 86.669304 ,  81.       ,  49.334652 ],\n",
      "         [ 90.995804 ,  81.713684 ,  49.713688 ],\n",
      "         ...,\n",
      "         [ 52.917297 ,  45.61153  ,  35.305767 ],\n",
      "         [ 54.336575 ,  46.557716 ,  35.77886  ],\n",
      "         [ 55.       ,  47.5039   ,  35.74805  ]],\n",
      "\n",
      "        [[ 91.04286  ,  81.52143  ,  52.564297 ],\n",
      "         [ 88.561676 ,  81.       ,  50.280838 ],\n",
      "         [ 87.68416  ,  81.24059  ,  49.240593 ],\n",
      "         ...,\n",
      "         [ 55.       ,  47.373558 ,  35.81322  ],\n",
      "         [ 55.       ,  48.31974  ,  35.34013  ],\n",
      "         [ 54.86704  ,  48.468147 ,  35.13296  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 96.1505   ,  89.1505   ,  60.150494 ],\n",
      "         [ 97.2417   ,  90.09668  ,  61.       ],\n",
      "         [ 99.607155 ,  91.04286  ,  61.       ],\n",
      "         ...,\n",
      "         [138.45148  ,  55.42475  ,  35.849506 ],\n",
      "         [141.       ,  54.08748  ,  34.08748  ],\n",
      "         [142.68637  ,  53.674545 ,  33.337273 ]],\n",
      "\n",
      "        [[ 99.2813   ,  90.91252  ,  61.       ],\n",
      "         [101.64676  ,  91.8587   ,  61.       ],\n",
      "         [ 99.585335 ,  89.98778  ,  59.792667 ],\n",
      "         ...,\n",
      "         [135.61293  ,  55.897846 ,  36.79569  ],\n",
      "         [140.899    ,  55.01683  ,  35.033665 ],\n",
      "         [141.       ,  53.271637 ,  33.271637 ]],\n",
      "\n",
      "        [[ 99.976364 ,  90.31364  ,  59.988182 ],\n",
      "         [ 97.13781  ,  87.94817  ,  58.568905 ],\n",
      "         [ 95.716545 ,  86.43308  ,  58.       ],\n",
      "         ...,\n",
      "         [135.37094  ,  57.48375  ,  37.       ],\n",
      "         [138.06046  ,  55.489925 ,  35.979847 ],\n",
      "         [141.       ,  54.217823 ,  34.217823 ]]]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch_data[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch_data[0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros(shape=(len(ordered_imgs), 7, 7, 2048))\n",
    "train_labels = np.zeros(shape=(len(ordered_imgs),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = res_fifty.predict(inputs_batch)\n",
    "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= len(ordered_imgs):\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (len(ordered_imgs), 7 * 7 * 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(train_features.shape[0], len(ordered_imgs)//5, replace=False)\n",
    "features = train_features[indices, :]\n",
    "tlabels = train_labels[indices,:]\n",
    "i,j = np.where(train_labels==1)\n",
    "t_labels = j[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputCodeClassifier(code_size=1.5,\n",
       "           estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=69,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=None, random_state=420)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OutputCodeClassifier as occ\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features,tlabels,test_size = 0.1)\n",
    "clf = occ(SVC(random_state=69), random_state= 420)\n",
    "clf.fit(features, t_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.random.choice(train_features.shape[0], len(ordered_imgs)//10, replace=False)\n",
    "test_features = train_features[test_indices, :]\n",
    "test_labels = j[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ouput = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229508196721312"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "occ produces 0.63 accuracy w/ 3662//5 train images, frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
